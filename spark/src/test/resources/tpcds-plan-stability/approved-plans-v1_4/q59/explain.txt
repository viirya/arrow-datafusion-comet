== Physical Plan ==
TakeOrderedAndProject (47)
+- * Project (46)
   +- * BroadcastHashJoin Inner BuildRight (45)
      :- * Project (27)
      :  +- * BroadcastHashJoin Inner BuildRight (26)
      :     :- * Project (20)
      :     :  +- * BroadcastHashJoin Inner BuildRight (19)
      :     :     :- * HashAggregate (14)
      :     :     :  +- * ColumnarToRow (13)
      :     :     :     +- CometColumnarExchange (12)
      :     :     :        +- RowToColumnar (11)
      :     :     :           +- * HashAggregate (10)
      :     :     :              +- * Project (9)
      :     :     :                 +- * BroadcastHashJoin Inner BuildRight (8)
      :     :     :                    :- * ColumnarToRow (3)
      :     :     :                    :  +- CometFilter (2)
      :     :     :                    :     +- CometScan parquet spark_catalog.default.store_sales (1)
      :     :     :                    +- BroadcastExchange (7)
      :     :     :                       +- * ColumnarToRow (6)
      :     :     :                          +- CometFilter (5)
      :     :     :                             +- CometScan parquet spark_catalog.default.date_dim (4)
      :     :     +- BroadcastExchange (18)
      :     :        +- * ColumnarToRow (17)
      :     :           +- CometFilter (16)
      :     :              +- CometScan parquet spark_catalog.default.store (15)
      :     +- BroadcastExchange (25)
      :        +- * ColumnarToRow (24)
      :           +- CometProject (23)
      :              +- CometFilter (22)
      :                 +- CometScan parquet spark_catalog.default.date_dim (21)
      +- BroadcastExchange (44)
         +- * Project (43)
            +- * BroadcastHashJoin Inner BuildRight (42)
               :- * Project (36)
               :  +- * BroadcastHashJoin Inner BuildRight (35)
               :     :- * HashAggregate (30)
               :     :  +- * ColumnarToRow (29)
               :     :     +- ReusedExchange (28)
               :     +- BroadcastExchange (34)
               :        +- * ColumnarToRow (33)
               :           +- CometFilter (32)
               :              +- CometScan parquet spark_catalog.default.store (31)
               +- BroadcastExchange (41)
                  +- * ColumnarToRow (40)
                     +- CometProject (39)
                        +- CometFilter (38)
                           +- CometScan parquet spark_catalog.default.date_dim (37)


(unknown) Scan parquet spark_catalog.default.store_sales
Output [3]: [ss_store_sk#1, ss_sales_price#2, ss_sold_date_sk#3]
Batched: true
Location: InMemoryFileIndex []
PartitionFilters: [isnotnull(ss_sold_date_sk#3)]
PushedFilters: [IsNotNull(ss_store_sk)]
ReadSchema: struct<ss_store_sk:int,ss_sales_price:decimal(7,2)>

(2) CometFilter
Input [3]: [ss_store_sk#1, ss_sales_price#2, ss_sold_date_sk#3]
Condition : isnotnull(ss_store_sk#1)

(3) ColumnarToRow [codegen id : 2]
Input [3]: [ss_store_sk#1, ss_sales_price#2, ss_sold_date_sk#3]

(unknown) Scan parquet spark_catalog.default.date_dim
Output [3]: [d_date_sk#4, d_week_seq#5, d_day_name#6]
Batched: true
Location [not included in comparison]/{warehouse_dir}/date_dim]
PushedFilters: [IsNotNull(d_date_sk), IsNotNull(d_week_seq)]
ReadSchema: struct<d_date_sk:int,d_week_seq:int,d_day_name:string>

(5) CometFilter
Input [3]: [d_date_sk#4, d_week_seq#5, d_day_name#6]
Condition : (isnotnull(d_date_sk#4) AND isnotnull(d_week_seq#5))

(6) ColumnarToRow [codegen id : 1]
Input [3]: [d_date_sk#4, d_week_seq#5, d_day_name#6]

(7) BroadcastExchange
Input [3]: [d_date_sk#4, d_week_seq#5, d_day_name#6]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=1]

(8) BroadcastHashJoin [codegen id : 2]
Left keys [1]: [ss_sold_date_sk#3]
Right keys [1]: [d_date_sk#4]
Join type: Inner
Join condition: None

(9) Project [codegen id : 2]
Output [4]: [ss_store_sk#1, ss_sales_price#2, d_week_seq#5, d_day_name#6]
Input [6]: [ss_store_sk#1, ss_sales_price#2, ss_sold_date_sk#3, d_date_sk#4, d_week_seq#5, d_day_name#6]

(10) HashAggregate [codegen id : 2]
Input [4]: [ss_store_sk#1, ss_sales_price#2, d_week_seq#5, d_day_name#6]
Keys [2]: [d_week_seq#5, ss_store_sk#1]
Functions [7]: [partial_sum(UnscaledValue(CASE WHEN (d_day_name#6 = Sunday   ) THEN ss_sales_price#2 END)), partial_sum(UnscaledValue(CASE WHEN (d_day_name#6 = Monday   ) THEN ss_sales_price#2 END)), partial_sum(UnscaledValue(CASE WHEN (d_day_name#6 = Tuesday  ) THEN ss_sales_price#2 END)), partial_sum(UnscaledValue(CASE WHEN (d_day_name#6 = Wednesday) THEN ss_sales_price#2 END)), partial_sum(UnscaledValue(CASE WHEN (d_day_name#6 = Thursday ) THEN ss_sales_price#2 END)), partial_sum(UnscaledValue(CASE WHEN (d_day_name#6 = Friday   ) THEN ss_sales_price#2 END)), partial_sum(UnscaledValue(CASE WHEN (d_day_name#6 = Saturday ) THEN ss_sales_price#2 END))]
Aggregate Attributes [7]: [sum#7, sum#8, sum#9, sum#10, sum#11, sum#12, sum#13]
Results [9]: [d_week_seq#5, ss_store_sk#1, sum#14, sum#15, sum#16, sum#17, sum#18, sum#19, sum#20]

(11) RowToColumnar
Input [9]: [d_week_seq#5, ss_store_sk#1, sum#14, sum#15, sum#16, sum#17, sum#18, sum#19, sum#20]

(12) CometColumnarExchange
Input [9]: [d_week_seq#5, ss_store_sk#1, sum#14, sum#15, sum#16, sum#17, sum#18, sum#19, sum#20]
Arguments: hashpartitioning(d_week_seq#5, ss_store_sk#1, 5), ENSURE_REQUIREMENTS, CometColumnarShuffle, [plan_id=2]

(13) ColumnarToRow [codegen id : 10]
Input [9]: [d_week_seq#5, ss_store_sk#1, sum#14, sum#15, sum#16, sum#17, sum#18, sum#19, sum#20]

(14) HashAggregate [codegen id : 10]
Input [9]: [d_week_seq#5, ss_store_sk#1, sum#14, sum#15, sum#16, sum#17, sum#18, sum#19, sum#20]
Keys [2]: [d_week_seq#5, ss_store_sk#1]
Functions [7]: [sum(UnscaledValue(CASE WHEN (d_day_name#6 = Sunday   ) THEN ss_sales_price#2 END)), sum(UnscaledValue(CASE WHEN (d_day_name#6 = Monday   ) THEN ss_sales_price#2 END)), sum(UnscaledValue(CASE WHEN (d_day_name#6 = Tuesday  ) THEN ss_sales_price#2 END)), sum(UnscaledValue(CASE WHEN (d_day_name#6 = Wednesday) THEN ss_sales_price#2 END)), sum(UnscaledValue(CASE WHEN (d_day_name#6 = Thursday ) THEN ss_sales_price#2 END)), sum(UnscaledValue(CASE WHEN (d_day_name#6 = Friday   ) THEN ss_sales_price#2 END)), sum(UnscaledValue(CASE WHEN (d_day_name#6 = Saturday ) THEN ss_sales_price#2 END))]
Aggregate Attributes [7]: [sum(UnscaledValue(CASE WHEN (d_day_name#6 = Sunday   ) THEN ss_sales_price#2 END))#21, sum(UnscaledValue(CASE WHEN (d_day_name#6 = Monday   ) THEN ss_sales_price#2 END))#22, sum(UnscaledValue(CASE WHEN (d_day_name#6 = Tuesday  ) THEN ss_sales_price#2 END))#23, sum(UnscaledValue(CASE WHEN (d_day_name#6 = Wednesday) THEN ss_sales_price#2 END))#24, sum(UnscaledValue(CASE WHEN (d_day_name#6 = Thursday ) THEN ss_sales_price#2 END))#25, sum(UnscaledValue(CASE WHEN (d_day_name#6 = Friday   ) THEN ss_sales_price#2 END))#26, sum(UnscaledValue(CASE WHEN (d_day_name#6 = Saturday ) THEN ss_sales_price#2 END))#27]
Results [9]: [d_week_seq#5, ss_store_sk#1, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#6 = Sunday   ) THEN ss_sales_price#2 END))#21,17,2) AS sun_sales#28, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#6 = Monday   ) THEN ss_sales_price#2 END))#22,17,2) AS mon_sales#29, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#6 = Tuesday  ) THEN ss_sales_price#2 END))#23,17,2) AS tue_sales#30, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#6 = Wednesday) THEN ss_sales_price#2 END))#24,17,2) AS wed_sales#31, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#6 = Thursday ) THEN ss_sales_price#2 END))#25,17,2) AS thu_sales#32, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#6 = Friday   ) THEN ss_sales_price#2 END))#26,17,2) AS fri_sales#33, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#6 = Saturday ) THEN ss_sales_price#2 END))#27,17,2) AS sat_sales#34]

(unknown) Scan parquet spark_catalog.default.store
Output [3]: [s_store_sk#35, s_store_id#36, s_store_name#37]
Batched: true
Location [not included in comparison]/{warehouse_dir}/store]
PushedFilters: [IsNotNull(s_store_sk), IsNotNull(s_store_id)]
ReadSchema: struct<s_store_sk:int,s_store_id:string,s_store_name:string>

(16) CometFilter
Input [3]: [s_store_sk#35, s_store_id#36, s_store_name#37]
Condition : (isnotnull(s_store_sk#35) AND isnotnull(s_store_id#36))

(17) ColumnarToRow [codegen id : 3]
Input [3]: [s_store_sk#35, s_store_id#36, s_store_name#37]

(18) BroadcastExchange
Input [3]: [s_store_sk#35, s_store_id#36, s_store_name#37]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=3]

(19) BroadcastHashJoin [codegen id : 10]
Left keys [1]: [ss_store_sk#1]
Right keys [1]: [s_store_sk#35]
Join type: Inner
Join condition: None

(20) Project [codegen id : 10]
Output [10]: [d_week_seq#5, sun_sales#28, mon_sales#29, tue_sales#30, wed_sales#31, thu_sales#32, fri_sales#33, sat_sales#34, s_store_id#36, s_store_name#37]
Input [12]: [d_week_seq#5, ss_store_sk#1, sun_sales#28, mon_sales#29, tue_sales#30, wed_sales#31, thu_sales#32, fri_sales#33, sat_sales#34, s_store_sk#35, s_store_id#36, s_store_name#37]

(unknown) Scan parquet spark_catalog.default.date_dim
Output [2]: [d_month_seq#38, d_week_seq#39]
Batched: true
Location [not included in comparison]/{warehouse_dir}/date_dim]
PushedFilters: [IsNotNull(d_month_seq), GreaterThanOrEqual(d_month_seq,1212), LessThanOrEqual(d_month_seq,1223), IsNotNull(d_week_seq)]
ReadSchema: struct<d_month_seq:int,d_week_seq:int>

(22) CometFilter
Input [2]: [d_month_seq#38, d_week_seq#39]
Condition : (((isnotnull(d_month_seq#38) AND (d_month_seq#38 >= 1212)) AND (d_month_seq#38 <= 1223)) AND isnotnull(d_week_seq#39))

(23) CometProject
Input [2]: [d_month_seq#38, d_week_seq#39]
Arguments: [d_week_seq#39], [d_week_seq#39]

(24) ColumnarToRow [codegen id : 4]
Input [1]: [d_week_seq#39]

(25) BroadcastExchange
Input [1]: [d_week_seq#39]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=4]

(26) BroadcastHashJoin [codegen id : 10]
Left keys [1]: [d_week_seq#5]
Right keys [1]: [d_week_seq#39]
Join type: Inner
Join condition: None

(27) Project [codegen id : 10]
Output [10]: [s_store_name#37 AS s_store_name1#40, d_week_seq#5 AS d_week_seq1#41, s_store_id#36 AS s_store_id1#42, sun_sales#28 AS sun_sales1#43, mon_sales#29 AS mon_sales1#44, tue_sales#30 AS tue_sales1#45, wed_sales#31 AS wed_sales1#46, thu_sales#32 AS thu_sales1#47, fri_sales#33 AS fri_sales1#48, sat_sales#34 AS sat_sales1#49]
Input [11]: [d_week_seq#5, sun_sales#28, mon_sales#29, tue_sales#30, wed_sales#31, thu_sales#32, fri_sales#33, sat_sales#34, s_store_id#36, s_store_name#37, d_week_seq#39]

(28) ReusedExchange [Reuses operator id: 12]
Output [9]: [d_week_seq#5, ss_store_sk#1, sum#50, sum#51, sum#52, sum#53, sum#54, sum#55, sum#56]

(29) ColumnarToRow [codegen id : 9]
Input [9]: [d_week_seq#5, ss_store_sk#1, sum#50, sum#51, sum#52, sum#53, sum#54, sum#55, sum#56]

(30) HashAggregate [codegen id : 9]
Input [9]: [d_week_seq#5, ss_store_sk#1, sum#50, sum#51, sum#52, sum#53, sum#54, sum#55, sum#56]
Keys [2]: [d_week_seq#5, ss_store_sk#1]
Functions [7]: [sum(UnscaledValue(CASE WHEN (d_day_name#6 = Sunday   ) THEN ss_sales_price#2 END)), sum(UnscaledValue(CASE WHEN (d_day_name#6 = Monday   ) THEN ss_sales_price#2 END)), sum(UnscaledValue(CASE WHEN (d_day_name#6 = Tuesday  ) THEN ss_sales_price#2 END)), sum(UnscaledValue(CASE WHEN (d_day_name#6 = Wednesday) THEN ss_sales_price#2 END)), sum(UnscaledValue(CASE WHEN (d_day_name#6 = Thursday ) THEN ss_sales_price#2 END)), sum(UnscaledValue(CASE WHEN (d_day_name#6 = Friday   ) THEN ss_sales_price#2 END)), sum(UnscaledValue(CASE WHEN (d_day_name#6 = Saturday ) THEN ss_sales_price#2 END))]
Aggregate Attributes [7]: [sum(UnscaledValue(CASE WHEN (d_day_name#6 = Sunday   ) THEN ss_sales_price#2 END))#21, sum(UnscaledValue(CASE WHEN (d_day_name#6 = Monday   ) THEN ss_sales_price#2 END))#22, sum(UnscaledValue(CASE WHEN (d_day_name#6 = Tuesday  ) THEN ss_sales_price#2 END))#23, sum(UnscaledValue(CASE WHEN (d_day_name#6 = Wednesday) THEN ss_sales_price#2 END))#24, sum(UnscaledValue(CASE WHEN (d_day_name#6 = Thursday ) THEN ss_sales_price#2 END))#25, sum(UnscaledValue(CASE WHEN (d_day_name#6 = Friday   ) THEN ss_sales_price#2 END))#26, sum(UnscaledValue(CASE WHEN (d_day_name#6 = Saturday ) THEN ss_sales_price#2 END))#27]
Results [9]: [d_week_seq#5, ss_store_sk#1, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#6 = Sunday   ) THEN ss_sales_price#2 END))#21,17,2) AS sun_sales#28, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#6 = Monday   ) THEN ss_sales_price#2 END))#22,17,2) AS mon_sales#29, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#6 = Tuesday  ) THEN ss_sales_price#2 END))#23,17,2) AS tue_sales#30, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#6 = Wednesday) THEN ss_sales_price#2 END))#24,17,2) AS wed_sales#31, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#6 = Thursday ) THEN ss_sales_price#2 END))#25,17,2) AS thu_sales#32, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#6 = Friday   ) THEN ss_sales_price#2 END))#26,17,2) AS fri_sales#33, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#6 = Saturday ) THEN ss_sales_price#2 END))#27,17,2) AS sat_sales#34]

(unknown) Scan parquet spark_catalog.default.store
Output [2]: [s_store_sk#57, s_store_id#58]
Batched: true
Location [not included in comparison]/{warehouse_dir}/store]
PushedFilters: [IsNotNull(s_store_sk), IsNotNull(s_store_id)]
ReadSchema: struct<s_store_sk:int,s_store_id:string>

(32) CometFilter
Input [2]: [s_store_sk#57, s_store_id#58]
Condition : (isnotnull(s_store_sk#57) AND isnotnull(s_store_id#58))

(33) ColumnarToRow [codegen id : 7]
Input [2]: [s_store_sk#57, s_store_id#58]

(34) BroadcastExchange
Input [2]: [s_store_sk#57, s_store_id#58]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=5]

(35) BroadcastHashJoin [codegen id : 9]
Left keys [1]: [ss_store_sk#1]
Right keys [1]: [s_store_sk#57]
Join type: Inner
Join condition: None

(36) Project [codegen id : 9]
Output [9]: [d_week_seq#5, sun_sales#28, mon_sales#29, tue_sales#30, wed_sales#31, thu_sales#32, fri_sales#33, sat_sales#34, s_store_id#58]
Input [11]: [d_week_seq#5, ss_store_sk#1, sun_sales#28, mon_sales#29, tue_sales#30, wed_sales#31, thu_sales#32, fri_sales#33, sat_sales#34, s_store_sk#57, s_store_id#58]

(unknown) Scan parquet spark_catalog.default.date_dim
Output [2]: [d_month_seq#59, d_week_seq#60]
Batched: true
Location [not included in comparison]/{warehouse_dir}/date_dim]
PushedFilters: [IsNotNull(d_month_seq), GreaterThanOrEqual(d_month_seq,1224), LessThanOrEqual(d_month_seq,1235), IsNotNull(d_week_seq)]
ReadSchema: struct<d_month_seq:int,d_week_seq:int>

(38) CometFilter
Input [2]: [d_month_seq#59, d_week_seq#60]
Condition : (((isnotnull(d_month_seq#59) AND (d_month_seq#59 >= 1224)) AND (d_month_seq#59 <= 1235)) AND isnotnull(d_week_seq#60))

(39) CometProject
Input [2]: [d_month_seq#59, d_week_seq#60]
Arguments: [d_week_seq#60], [d_week_seq#60]

(40) ColumnarToRow [codegen id : 8]
Input [1]: [d_week_seq#60]

(41) BroadcastExchange
Input [1]: [d_week_seq#60]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=6]

(42) BroadcastHashJoin [codegen id : 9]
Left keys [1]: [d_week_seq#5]
Right keys [1]: [d_week_seq#60]
Join type: Inner
Join condition: None

(43) Project [codegen id : 9]
Output [9]: [d_week_seq#5 AS d_week_seq2#61, s_store_id#58 AS s_store_id2#62, sun_sales#28 AS sun_sales2#63, mon_sales#29 AS mon_sales2#64, tue_sales#30 AS tue_sales2#65, wed_sales#31 AS wed_sales2#66, thu_sales#32 AS thu_sales2#67, fri_sales#33 AS fri_sales2#68, sat_sales#34 AS sat_sales2#69]
Input [10]: [d_week_seq#5, sun_sales#28, mon_sales#29, tue_sales#30, wed_sales#31, thu_sales#32, fri_sales#33, sat_sales#34, s_store_id#58, d_week_seq#60]

(44) BroadcastExchange
Input [9]: [d_week_seq2#61, s_store_id2#62, sun_sales2#63, mon_sales2#64, tue_sales2#65, wed_sales2#66, thu_sales2#67, fri_sales2#68, sat_sales2#69]
Arguments: HashedRelationBroadcastMode(List(input[1, string, true], (input[0, int, true] - 52)),false), [plan_id=7]

(45) BroadcastHashJoin [codegen id : 10]
Left keys [2]: [s_store_id1#42, d_week_seq1#41]
Right keys [2]: [s_store_id2#62, (d_week_seq2#61 - 52)]
Join type: Inner
Join condition: None

(46) Project [codegen id : 10]
Output [10]: [s_store_name1#40, s_store_id1#42, d_week_seq1#41, (sun_sales1#43 / sun_sales2#63) AS (sun_sales1 / sun_sales2)#70, (mon_sales1#44 / mon_sales2#64) AS (mon_sales1 / mon_sales2)#71, (tue_sales1#45 / tue_sales2#65) AS (tue_sales1 / tue_sales2)#72, (wed_sales1#46 / wed_sales2#66) AS (wed_sales1 / wed_sales2)#73, (thu_sales1#47 / thu_sales2#67) AS (thu_sales1 / thu_sales2)#74, (fri_sales1#48 / fri_sales2#68) AS (fri_sales1 / fri_sales2)#75, (sat_sales1#49 / sat_sales2#69) AS (sat_sales1 / sat_sales2)#76]
Input [19]: [s_store_name1#40, d_week_seq1#41, s_store_id1#42, sun_sales1#43, mon_sales1#44, tue_sales1#45, wed_sales1#46, thu_sales1#47, fri_sales1#48, sat_sales1#49, d_week_seq2#61, s_store_id2#62, sun_sales2#63, mon_sales2#64, tue_sales2#65, wed_sales2#66, thu_sales2#67, fri_sales2#68, sat_sales2#69]

(47) TakeOrderedAndProject
Input [10]: [s_store_name1#40, s_store_id1#42, d_week_seq1#41, (sun_sales1 / sun_sales2)#70, (mon_sales1 / mon_sales2)#71, (tue_sales1 / tue_sales2)#72, (wed_sales1 / wed_sales2)#73, (thu_sales1 / thu_sales2)#74, (fri_sales1 / fri_sales2)#75, (sat_sales1 / sat_sales2)#76]
Arguments: 100, [s_store_name1#40 ASC NULLS FIRST, s_store_id1#42 ASC NULLS FIRST, d_week_seq1#41 ASC NULLS FIRST], [s_store_name1#40, s_store_id1#42, d_week_seq1#41, (sun_sales1 / sun_sales2)#70, (mon_sales1 / mon_sales2)#71, (tue_sales1 / tue_sales2)#72, (wed_sales1 / wed_sales2)#73, (thu_sales1 / thu_sales2)#74, (fri_sales1 / fri_sales2)#75, (sat_sales1 / sat_sales2)#76]

