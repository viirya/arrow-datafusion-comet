== Physical Plan ==
* ColumnarToRow (23)
+- CometTakeOrderedAndProject (22)
   +- CometHashAggregate (21)
      +- CometColumnarExchange (20)
         +- RowToColumnar (19)
            +- * HashAggregate (18)
               +- * Project (17)
                  +- * BroadcastHashJoin Inner BuildRight (16)
                     :- * Project (10)
                     :  +- * BroadcastHashJoin Inner BuildRight (9)
                     :     :- * ColumnarToRow (4)
                     :     :  +- CometProject (3)
                     :     :     +- CometFilter (2)
                     :     :        +- CometScan parquet spark_catalog.default.date_dim (1)
                     :     +- BroadcastExchange (8)
                     :        +- * ColumnarToRow (7)
                     :           +- CometFilter (6)
                     :              +- CometScan parquet spark_catalog.default.store_sales (5)
                     +- BroadcastExchange (15)
                        +- * ColumnarToRow (14)
                           +- CometProject (13)
                              +- CometFilter (12)
                                 +- CometScan parquet spark_catalog.default.store (11)


(unknown) Scan parquet spark_catalog.default.date_dim
Output [3]: [d_date_sk#1, d_year#2, d_day_name#3]
Batched: true
Location [not included in comparison]/{warehouse_dir}/date_dim]
PushedFilters: [IsNotNull(d_year), EqualTo(d_year,2000), IsNotNull(d_date_sk)]
ReadSchema: struct<d_date_sk:int,d_year:int,d_day_name:string>

(2) CometFilter
Input [3]: [d_date_sk#1, d_year#2, d_day_name#3]
Condition : ((isnotnull(d_year#2) AND (d_year#2 = 2000)) AND isnotnull(d_date_sk#1))

(3) CometProject
Input [3]: [d_date_sk#1, d_year#2, d_day_name#3]
Arguments: [d_date_sk#1, d_day_name#3], [d_date_sk#1, d_day_name#3]

(4) ColumnarToRow [codegen id : 3]
Input [2]: [d_date_sk#1, d_day_name#3]

(unknown) Scan parquet spark_catalog.default.store_sales
Output [3]: [ss_store_sk#4, ss_sales_price#5, ss_sold_date_sk#6]
Batched: true
Location: InMemoryFileIndex []
PartitionFilters: [isnotnull(ss_sold_date_sk#6), dynamicpruningexpression(true)]
PushedFilters: [IsNotNull(ss_store_sk)]
ReadSchema: struct<ss_store_sk:int,ss_sales_price:decimal(7,2)>

(6) CometFilter
Input [3]: [ss_store_sk#4, ss_sales_price#5, ss_sold_date_sk#6]
Condition : isnotnull(ss_store_sk#4)

(7) ColumnarToRow [codegen id : 1]
Input [3]: [ss_store_sk#4, ss_sales_price#5, ss_sold_date_sk#6]

(8) BroadcastExchange
Input [3]: [ss_store_sk#4, ss_sales_price#5, ss_sold_date_sk#6]
Arguments: HashedRelationBroadcastMode(List(cast(input[2, int, true] as bigint)),false), [plan_id=1]

(9) BroadcastHashJoin [codegen id : 3]
Left keys [1]: [d_date_sk#1]
Right keys [1]: [ss_sold_date_sk#6]
Join type: Inner
Join condition: None

(10) Project [codegen id : 3]
Output [3]: [d_day_name#3, ss_store_sk#4, ss_sales_price#5]
Input [5]: [d_date_sk#1, d_day_name#3, ss_store_sk#4, ss_sales_price#5, ss_sold_date_sk#6]

(unknown) Scan parquet spark_catalog.default.store
Output [4]: [s_store_sk#7, s_store_id#8, s_store_name#9, s_gmt_offset#10]
Batched: true
Location [not included in comparison]/{warehouse_dir}/store]
PushedFilters: [IsNotNull(s_gmt_offset), EqualTo(s_gmt_offset,-5.00), IsNotNull(s_store_sk)]
ReadSchema: struct<s_store_sk:int,s_store_id:string,s_store_name:string,s_gmt_offset:decimal(5,2)>

(12) CometFilter
Input [4]: [s_store_sk#7, s_store_id#8, s_store_name#9, s_gmt_offset#10]
Condition : ((isnotnull(s_gmt_offset#10) AND (s_gmt_offset#10 = -5.00)) AND isnotnull(s_store_sk#7))

(13) CometProject
Input [4]: [s_store_sk#7, s_store_id#8, s_store_name#9, s_gmt_offset#10]
Arguments: [s_store_sk#7, s_store_id#8, s_store_name#9], [s_store_sk#7, s_store_id#8, s_store_name#9]

(14) ColumnarToRow [codegen id : 2]
Input [3]: [s_store_sk#7, s_store_id#8, s_store_name#9]

(15) BroadcastExchange
Input [3]: [s_store_sk#7, s_store_id#8, s_store_name#9]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=2]

(16) BroadcastHashJoin [codegen id : 3]
Left keys [1]: [ss_store_sk#4]
Right keys [1]: [s_store_sk#7]
Join type: Inner
Join condition: None

(17) Project [codegen id : 3]
Output [4]: [d_day_name#3, ss_sales_price#5, s_store_id#8, s_store_name#9]
Input [6]: [d_day_name#3, ss_store_sk#4, ss_sales_price#5, s_store_sk#7, s_store_id#8, s_store_name#9]

(18) HashAggregate [codegen id : 3]
Input [4]: [d_day_name#3, ss_sales_price#5, s_store_id#8, s_store_name#9]
Keys [2]: [s_store_name#9, s_store_id#8]
Functions [7]: [partial_sum(UnscaledValue(CASE WHEN (d_day_name#3 = Sunday   ) THEN ss_sales_price#5 END)), partial_sum(UnscaledValue(CASE WHEN (d_day_name#3 = Monday   ) THEN ss_sales_price#5 END)), partial_sum(UnscaledValue(CASE WHEN (d_day_name#3 = Tuesday  ) THEN ss_sales_price#5 END)), partial_sum(UnscaledValue(CASE WHEN (d_day_name#3 = Wednesday) THEN ss_sales_price#5 END)), partial_sum(UnscaledValue(CASE WHEN (d_day_name#3 = Thursday ) THEN ss_sales_price#5 END)), partial_sum(UnscaledValue(CASE WHEN (d_day_name#3 = Friday   ) THEN ss_sales_price#5 END)), partial_sum(UnscaledValue(CASE WHEN (d_day_name#3 = Saturday ) THEN ss_sales_price#5 END))]
Aggregate Attributes [7]: [sum#11, sum#12, sum#13, sum#14, sum#15, sum#16, sum#17]
Results [9]: [s_store_name#9, s_store_id#8, sum#18, sum#19, sum#20, sum#21, sum#22, sum#23, sum#24]

(19) RowToColumnar
Input [9]: [s_store_name#9, s_store_id#8, sum#18, sum#19, sum#20, sum#21, sum#22, sum#23, sum#24]

(20) CometColumnarExchange
Input [9]: [s_store_name#9, s_store_id#8, sum#18, sum#19, sum#20, sum#21, sum#22, sum#23, sum#24]
Arguments: hashpartitioning(s_store_name#9, s_store_id#8, 5), ENSURE_REQUIREMENTS, CometColumnarShuffle, [plan_id=3]

(21) CometHashAggregate
Input [9]: [s_store_name#9, s_store_id#8, sum#18, sum#19, sum#20, sum#21, sum#22, sum#23, sum#24]
Keys [2]: [s_store_name#9, s_store_id#8]
Functions [7]: [sum(UnscaledValue(CASE WHEN (d_day_name#3 = Sunday   ) THEN ss_sales_price#5 END)), sum(UnscaledValue(CASE WHEN (d_day_name#3 = Monday   ) THEN ss_sales_price#5 END)), sum(UnscaledValue(CASE WHEN (d_day_name#3 = Tuesday  ) THEN ss_sales_price#5 END)), sum(UnscaledValue(CASE WHEN (d_day_name#3 = Wednesday) THEN ss_sales_price#5 END)), sum(UnscaledValue(CASE WHEN (d_day_name#3 = Thursday ) THEN ss_sales_price#5 END)), sum(UnscaledValue(CASE WHEN (d_day_name#3 = Friday   ) THEN ss_sales_price#5 END)), sum(UnscaledValue(CASE WHEN (d_day_name#3 = Saturday ) THEN ss_sales_price#5 END))]

(22) CometTakeOrderedAndProject
Input [9]: [s_store_name#9, s_store_id#8, sun_sales#25, mon_sales#26, tue_sales#27, wed_sales#28, thu_sales#29, fri_sales#30, sat_sales#31]
Arguments: TakeOrderedAndProject(limit=100, orderBy=[s_store_name#9 ASC NULLS FIRST,s_store_id#8 ASC NULLS FIRST,sun_sales#25 ASC NULLS FIRST,mon_sales#26 ASC NULLS FIRST,tue_sales#27 ASC NULLS FIRST,wed_sales#28 ASC NULLS FIRST,thu_sales#29 ASC NULLS FIRST,fri_sales#30 ASC NULLS FIRST,sat_sales#31 ASC NULLS FIRST], output=[s_store_name#9,s_store_id#8,sun_sales#25,mon_sales#26,tue_sales#27,wed_sales#28,thu_sales#29,fri_sales#30,sat_sales#31]), 100, [s_store_name#9 ASC NULLS FIRST, s_store_id#8 ASC NULLS FIRST, sun_sales#25 ASC NULLS FIRST, mon_sales#26 ASC NULLS FIRST, tue_sales#27 ASC NULLS FIRST, wed_sales#28 ASC NULLS FIRST, thu_sales#29 ASC NULLS FIRST, fri_sales#30 ASC NULLS FIRST, sat_sales#31 ASC NULLS FIRST], [s_store_name#9, s_store_id#8, sun_sales#25, mon_sales#26, tue_sales#27, wed_sales#28, thu_sales#29, fri_sales#30, sat_sales#31]

(23) ColumnarToRow [codegen id : 4]
Input [9]: [s_store_name#9, s_store_id#8, sun_sales#25, mon_sales#26, tue_sales#27, wed_sales#28, thu_sales#29, fri_sales#30, sat_sales#31]

