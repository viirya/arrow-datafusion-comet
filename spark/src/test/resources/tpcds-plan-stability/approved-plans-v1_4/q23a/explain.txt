== Physical Plan ==
* ColumnarToRow (75)
+- CometHashAggregate (74)
   +- CometColumnarExchange (73)
      +- RowToColumnar (72)
         +- * HashAggregate (71)
            +- Union (70)
               :- * Project (50)
               :  +- * BroadcastHashJoin Inner BuildRight (49)
               :     :- * ColumnarToRow (47)
               :     :  +- CometProject (46)
               :     :     +- CometSortMergeJoin (45)
               :     :        :- CometSort (27)
               :     :        :  +- CometColumnarExchange (26)
               :     :        :     +- RowToColumnar (25)
               :     :        :        +- * Project (24)
               :     :        :           +- * BroadcastHashJoin LeftSemi BuildRight (23)
               :     :        :              :- * ColumnarToRow (2)
               :     :        :              :  +- CometScan parquet spark_catalog.default.catalog_sales (1)
               :     :        :              +- BroadcastExchange (22)
               :     :        :                 +- * ColumnarToRow (21)
               :     :        :                    +- CometProject (20)
               :     :        :                       +- CometFilter (19)
               :     :        :                          +- CometHashAggregate (18)
               :     :        :                             +- CometColumnarExchange (17)
               :     :        :                                +- RowToColumnar (16)
               :     :        :                                   +- * HashAggregate (15)
               :     :        :                                      +- * Project (14)
               :     :        :                                         +- * BroadcastHashJoin Inner BuildRight (13)
               :     :        :                                            :- * Project (8)
               :     :        :                                            :  +- * BroadcastHashJoin Inner BuildRight (7)
               :     :        :                                            :     :- * ColumnarToRow (5)
               :     :        :                                            :     :  +- CometFilter (4)
               :     :        :                                            :     :     +- CometScan parquet spark_catalog.default.store_sales (3)
               :     :        :                                            :     +- ReusedExchange (6)
               :     :        :                                            +- BroadcastExchange (12)
               :     :        :                                               +- * ColumnarToRow (11)
               :     :        :                                                  +- CometFilter (10)
               :     :        :                                                     +- CometScan parquet spark_catalog.default.item (9)
               :     :        +- CometSort (44)
               :     :           +- CometProject (43)
               :     :              +- CometFilter (42)
               :     :                 +- CometHashAggregate (41)
               :     :                    +- CometColumnarExchange (40)
               :     :                       +- RowToColumnar (39)
               :     :                          +- * HashAggregate (38)
               :     :                             +- * Project (37)
               :     :                                +- * BroadcastHashJoin Inner BuildRight (36)
               :     :                                   :- * ColumnarToRow (31)
               :     :                                   :  +- CometProject (30)
               :     :                                   :     +- CometFilter (29)
               :     :                                   :        +- CometScan parquet spark_catalog.default.store_sales (28)
               :     :                                   +- BroadcastExchange (35)
               :     :                                      +- * ColumnarToRow (34)
               :     :                                         +- CometFilter (33)
               :     :                                            +- CometScan parquet spark_catalog.default.customer (32)
               :     +- ReusedExchange (48)
               +- * Project (69)
                  +- * BroadcastHashJoin Inner BuildRight (68)
                     :- * ColumnarToRow (66)
                     :  +- CometProject (65)
                     :     +- CometSortMergeJoin (64)
                     :        :- CometSort (58)
                     :        :  +- CometColumnarExchange (57)
                     :        :     +- RowToColumnar (56)
                     :        :        +- * Project (55)
                     :        :           +- * BroadcastHashJoin LeftSemi BuildRight (54)
                     :        :              :- * ColumnarToRow (52)
                     :        :              :  +- CometScan parquet spark_catalog.default.web_sales (51)
                     :        :              +- ReusedExchange (53)
                     :        +- CometSort (63)
                     :           +- CometProject (62)
                     :              +- CometFilter (61)
                     :                 +- CometHashAggregate (60)
                     :                    +- ReusedExchange (59)
                     +- ReusedExchange (67)


(unknown) Scan parquet spark_catalog.default.catalog_sales
Output [5]: [cs_bill_customer_sk#1, cs_item_sk#2, cs_quantity#3, cs_list_price#4, cs_sold_date_sk#5]
Batched: true
Location: InMemoryFileIndex []
PartitionFilters: [isnotnull(cs_sold_date_sk#5), dynamicpruningexpression(cs_sold_date_sk#5 IN dynamicpruning#6)]
ReadSchema: struct<cs_bill_customer_sk:int,cs_item_sk:int,cs_quantity:int,cs_list_price:decimal(7,2)>

(2) ColumnarToRow [codegen id : 5]
Input [5]: [cs_bill_customer_sk#1, cs_item_sk#2, cs_quantity#3, cs_list_price#4, cs_sold_date_sk#5]

(unknown) Scan parquet spark_catalog.default.store_sales
Output [2]: [ss_item_sk#7, ss_sold_date_sk#8]
Batched: true
Location: InMemoryFileIndex []
PartitionFilters: [isnotnull(ss_sold_date_sk#8), dynamicpruningexpression(ss_sold_date_sk#8 IN dynamicpruning#9)]
PushedFilters: [IsNotNull(ss_item_sk)]
ReadSchema: struct<ss_item_sk:int>

(4) CometFilter
Input [2]: [ss_item_sk#7, ss_sold_date_sk#8]
Condition : isnotnull(ss_item_sk#7)

(5) ColumnarToRow [codegen id : 3]
Input [2]: [ss_item_sk#7, ss_sold_date_sk#8]

(6) ReusedExchange [Reuses operator id: 85]
Output [2]: [d_date_sk#10, d_date#11]

(7) BroadcastHashJoin [codegen id : 3]
Left keys [1]: [ss_sold_date_sk#8]
Right keys [1]: [d_date_sk#10]
Join type: Inner
Join condition: None

(8) Project [codegen id : 3]
Output [2]: [ss_item_sk#7, d_date#11]
Input [4]: [ss_item_sk#7, ss_sold_date_sk#8, d_date_sk#10, d_date#11]

(unknown) Scan parquet spark_catalog.default.item
Output [2]: [i_item_sk#12, i_item_desc#13]
Batched: true
Location [not included in comparison]/{warehouse_dir}/item]
PushedFilters: [IsNotNull(i_item_sk)]
ReadSchema: struct<i_item_sk:int,i_item_desc:string>

(10) CometFilter
Input [2]: [i_item_sk#12, i_item_desc#13]
Condition : isnotnull(i_item_sk#12)

(11) ColumnarToRow [codegen id : 2]
Input [2]: [i_item_sk#12, i_item_desc#13]

(12) BroadcastExchange
Input [2]: [i_item_sk#12, i_item_desc#13]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=1]

(13) BroadcastHashJoin [codegen id : 3]
Left keys [1]: [ss_item_sk#7]
Right keys [1]: [i_item_sk#12]
Join type: Inner
Join condition: None

(14) Project [codegen id : 3]
Output [3]: [d_date#11, i_item_sk#12, substr(i_item_desc#13, 1, 30) AS _groupingexpression#14]
Input [4]: [ss_item_sk#7, d_date#11, i_item_sk#12, i_item_desc#13]

(15) HashAggregate [codegen id : 3]
Input [3]: [d_date#11, i_item_sk#12, _groupingexpression#14]
Keys [3]: [_groupingexpression#14, i_item_sk#12, d_date#11]
Functions [1]: [partial_count(1)]
Aggregate Attributes [1]: [count#15]
Results [4]: [_groupingexpression#14, i_item_sk#12, d_date#11, count#16]

(16) RowToColumnar
Input [4]: [_groupingexpression#14, i_item_sk#12, d_date#11, count#16]

(17) CometColumnarExchange
Input [4]: [_groupingexpression#14, i_item_sk#12, d_date#11, count#16]
Arguments: hashpartitioning(_groupingexpression#14, i_item_sk#12, d_date#11, 5), ENSURE_REQUIREMENTS, CometColumnarShuffle, [plan_id=2]

(18) CometHashAggregate
Input [4]: [_groupingexpression#14, i_item_sk#12, d_date#11, count#16]
Keys [3]: [_groupingexpression#14, i_item_sk#12, d_date#11]
Functions [1]: [count(1)]

(19) CometFilter
Input [2]: [item_sk#17, cnt#18]
Condition : (cnt#18 > 4)

(20) CometProject
Input [2]: [item_sk#17, cnt#18]
Arguments: [item_sk#17], [item_sk#17]

(21) ColumnarToRow [codegen id : 4]
Input [1]: [item_sk#17]

(22) BroadcastExchange
Input [1]: [item_sk#17]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=3]

(23) BroadcastHashJoin [codegen id : 5]
Left keys [1]: [cs_item_sk#2]
Right keys [1]: [item_sk#17]
Join type: LeftSemi
Join condition: None

(24) Project [codegen id : 5]
Output [4]: [cs_bill_customer_sk#1, cs_quantity#3, cs_list_price#4, cs_sold_date_sk#5]
Input [5]: [cs_bill_customer_sk#1, cs_item_sk#2, cs_quantity#3, cs_list_price#4, cs_sold_date_sk#5]

(25) RowToColumnar
Input [4]: [cs_bill_customer_sk#1, cs_quantity#3, cs_list_price#4, cs_sold_date_sk#5]

(26) CometColumnarExchange
Input [4]: [cs_bill_customer_sk#1, cs_quantity#3, cs_list_price#4, cs_sold_date_sk#5]
Arguments: hashpartitioning(cs_bill_customer_sk#1, 5), ENSURE_REQUIREMENTS, CometColumnarShuffle, [plan_id=4]

(27) CometSort
Input [4]: [cs_bill_customer_sk#1, cs_quantity#3, cs_list_price#4, cs_sold_date_sk#5]
Arguments: [cs_bill_customer_sk#1, cs_quantity#3, cs_list_price#4, cs_sold_date_sk#5], [cs_bill_customer_sk#1 ASC NULLS FIRST]

(unknown) Scan parquet spark_catalog.default.store_sales
Output [4]: [ss_customer_sk#19, ss_quantity#20, ss_sales_price#21, ss_sold_date_sk#22]
Batched: true
Location [not included in comparison]/{warehouse_dir}/store_sales]
PushedFilters: [IsNotNull(ss_customer_sk)]
ReadSchema: struct<ss_customer_sk:int,ss_quantity:int,ss_sales_price:decimal(7,2)>

(29) CometFilter
Input [4]: [ss_customer_sk#19, ss_quantity#20, ss_sales_price#21, ss_sold_date_sk#22]
Condition : isnotnull(ss_customer_sk#19)

(30) CometProject
Input [4]: [ss_customer_sk#19, ss_quantity#20, ss_sales_price#21, ss_sold_date_sk#22]
Arguments: [ss_customer_sk#19, ss_quantity#20, ss_sales_price#21], [ss_customer_sk#19, ss_quantity#20, ss_sales_price#21]

(31) ColumnarToRow [codegen id : 7]
Input [3]: [ss_customer_sk#19, ss_quantity#20, ss_sales_price#21]

(unknown) Scan parquet spark_catalog.default.customer
Output [1]: [c_customer_sk#23]
Batched: true
Location [not included in comparison]/{warehouse_dir}/customer]
PushedFilters: [IsNotNull(c_customer_sk)]
ReadSchema: struct<c_customer_sk:int>

(33) CometFilter
Input [1]: [c_customer_sk#23]
Condition : isnotnull(c_customer_sk#23)

(34) ColumnarToRow [codegen id : 6]
Input [1]: [c_customer_sk#23]

(35) BroadcastExchange
Input [1]: [c_customer_sk#23]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=5]

(36) BroadcastHashJoin [codegen id : 7]
Left keys [1]: [ss_customer_sk#19]
Right keys [1]: [c_customer_sk#23]
Join type: Inner
Join condition: None

(37) Project [codegen id : 7]
Output [3]: [ss_quantity#20, ss_sales_price#21, c_customer_sk#23]
Input [4]: [ss_customer_sk#19, ss_quantity#20, ss_sales_price#21, c_customer_sk#23]

(38) HashAggregate [codegen id : 7]
Input [3]: [ss_quantity#20, ss_sales_price#21, c_customer_sk#23]
Keys [1]: [c_customer_sk#23]
Functions [1]: [partial_sum((cast(ss_quantity#20 as decimal(10,0)) * ss_sales_price#21))]
Aggregate Attributes [2]: [sum#24, isEmpty#25]
Results [3]: [c_customer_sk#23, sum#26, isEmpty#27]

(39) RowToColumnar
Input [3]: [c_customer_sk#23, sum#26, isEmpty#27]

(40) CometColumnarExchange
Input [3]: [c_customer_sk#23, sum#26, isEmpty#27]
Arguments: hashpartitioning(c_customer_sk#23, 5), ENSURE_REQUIREMENTS, CometColumnarShuffle, [plan_id=6]

(41) CometHashAggregate
Input [3]: [c_customer_sk#23, sum#26, isEmpty#27]
Keys [1]: [c_customer_sk#23]
Functions [1]: [sum((cast(ss_quantity#20 as decimal(10,0)) * ss_sales_price#21))]

(42) CometFilter
Input [2]: [c_customer_sk#23, ssales#28]
Condition : (isnotnull(ssales#28) AND (cast(ssales#28 as decimal(38,8)) > (0.500000 * Subquery scalar-subquery#29, [id=#30])))

(43) CometProject
Input [2]: [c_customer_sk#23, ssales#28]
Arguments: [c_customer_sk#23], [c_customer_sk#23]

(44) CometSort
Input [1]: [c_customer_sk#23]
Arguments: [c_customer_sk#23], [c_customer_sk#23 ASC NULLS FIRST]

(45) CometSortMergeJoin
Left output [4]: [cs_bill_customer_sk#1, cs_quantity#3, cs_list_price#4, cs_sold_date_sk#5]
Right output [1]: [c_customer_sk#23]
Arguments: [cs_bill_customer_sk#1], [c_customer_sk#23], LeftSemi

(46) CometProject
Input [4]: [cs_bill_customer_sk#1, cs_quantity#3, cs_list_price#4, cs_sold_date_sk#5]
Arguments: [cs_quantity#3, cs_list_price#4, cs_sold_date_sk#5], [cs_quantity#3, cs_list_price#4, cs_sold_date_sk#5]

(47) ColumnarToRow [codegen id : 9]
Input [3]: [cs_quantity#3, cs_list_price#4, cs_sold_date_sk#5]

(48) ReusedExchange [Reuses operator id: 80]
Output [1]: [d_date_sk#31]

(49) BroadcastHashJoin [codegen id : 9]
Left keys [1]: [cs_sold_date_sk#5]
Right keys [1]: [d_date_sk#31]
Join type: Inner
Join condition: None

(50) Project [codegen id : 9]
Output [1]: [(cast(cs_quantity#3 as decimal(10,0)) * cs_list_price#4) AS sales#32]
Input [4]: [cs_quantity#3, cs_list_price#4, cs_sold_date_sk#5, d_date_sk#31]

(unknown) Scan parquet spark_catalog.default.web_sales
Output [5]: [ws_item_sk#33, ws_bill_customer_sk#34, ws_quantity#35, ws_list_price#36, ws_sold_date_sk#37]
Batched: true
Location: InMemoryFileIndex []
PartitionFilters: [isnotnull(ws_sold_date_sk#37), dynamicpruningexpression(ws_sold_date_sk#37 IN dynamicpruning#38)]
ReadSchema: struct<ws_item_sk:int,ws_bill_customer_sk:int,ws_quantity:int,ws_list_price:decimal(7,2)>

(52) ColumnarToRow [codegen id : 14]
Input [5]: [ws_item_sk#33, ws_bill_customer_sk#34, ws_quantity#35, ws_list_price#36, ws_sold_date_sk#37]

(53) ReusedExchange [Reuses operator id: 22]
Output [1]: [item_sk#17]

(54) BroadcastHashJoin [codegen id : 14]
Left keys [1]: [ws_item_sk#33]
Right keys [1]: [item_sk#17]
Join type: LeftSemi
Join condition: None

(55) Project [codegen id : 14]
Output [4]: [ws_bill_customer_sk#34, ws_quantity#35, ws_list_price#36, ws_sold_date_sk#37]
Input [5]: [ws_item_sk#33, ws_bill_customer_sk#34, ws_quantity#35, ws_list_price#36, ws_sold_date_sk#37]

(56) RowToColumnar
Input [4]: [ws_bill_customer_sk#34, ws_quantity#35, ws_list_price#36, ws_sold_date_sk#37]

(57) CometColumnarExchange
Input [4]: [ws_bill_customer_sk#34, ws_quantity#35, ws_list_price#36, ws_sold_date_sk#37]
Arguments: hashpartitioning(ws_bill_customer_sk#34, 5), ENSURE_REQUIREMENTS, CometColumnarShuffle, [plan_id=7]

(58) CometSort
Input [4]: [ws_bill_customer_sk#34, ws_quantity#35, ws_list_price#36, ws_sold_date_sk#37]
Arguments: [ws_bill_customer_sk#34, ws_quantity#35, ws_list_price#36, ws_sold_date_sk#37], [ws_bill_customer_sk#34 ASC NULLS FIRST]

(59) ReusedExchange [Reuses operator id: 40]
Output [3]: [c_customer_sk#23, sum#26, isEmpty#27]

(60) CometHashAggregate
Input [3]: [c_customer_sk#23, sum#26, isEmpty#27]
Keys [1]: [c_customer_sk#23]
Functions [1]: [sum((cast(ss_quantity#20 as decimal(10,0)) * ss_sales_price#21))]

(61) CometFilter
Input [2]: [c_customer_sk#23, ssales#28]
Condition : (isnotnull(ssales#28) AND (cast(ssales#28 as decimal(38,8)) > (0.500000 * ReusedSubquery Subquery scalar-subquery#29, [id=#30])))

(62) CometProject
Input [2]: [c_customer_sk#23, ssales#28]
Arguments: [c_customer_sk#23], [c_customer_sk#23]

(63) CometSort
Input [1]: [c_customer_sk#23]
Arguments: [c_customer_sk#23], [c_customer_sk#23 ASC NULLS FIRST]

(64) CometSortMergeJoin
Left output [4]: [ws_bill_customer_sk#34, ws_quantity#35, ws_list_price#36, ws_sold_date_sk#37]
Right output [1]: [c_customer_sk#23]
Arguments: [ws_bill_customer_sk#34], [c_customer_sk#23], LeftSemi

(65) CometProject
Input [4]: [ws_bill_customer_sk#34, ws_quantity#35, ws_list_price#36, ws_sold_date_sk#37]
Arguments: [ws_quantity#35, ws_list_price#36, ws_sold_date_sk#37], [ws_quantity#35, ws_list_price#36, ws_sold_date_sk#37]

(66) ColumnarToRow [codegen id : 18]
Input [3]: [ws_quantity#35, ws_list_price#36, ws_sold_date_sk#37]

(67) ReusedExchange [Reuses operator id: 80]
Output [1]: [d_date_sk#39]

(68) BroadcastHashJoin [codegen id : 18]
Left keys [1]: [ws_sold_date_sk#37]
Right keys [1]: [d_date_sk#39]
Join type: Inner
Join condition: None

(69) Project [codegen id : 18]
Output [1]: [(cast(ws_quantity#35 as decimal(10,0)) * ws_list_price#36) AS sales#40]
Input [4]: [ws_quantity#35, ws_list_price#36, ws_sold_date_sk#37, d_date_sk#39]

(70) Union

(71) HashAggregate [codegen id : 19]
Input [1]: [sales#32]
Keys: []
Functions [1]: [partial_sum(sales#32)]
Aggregate Attributes [2]: [sum#41, isEmpty#42]
Results [2]: [sum#43, isEmpty#44]

(72) RowToColumnar
Input [2]: [sum#43, isEmpty#44]

(73) CometColumnarExchange
Input [2]: [sum#43, isEmpty#44]
Arguments: SinglePartition, ENSURE_REQUIREMENTS, CometColumnarShuffle, [plan_id=8]

(74) CometHashAggregate
Input [2]: [sum#43, isEmpty#44]
Keys: []
Functions [1]: [sum(sales#32)]

(75) ColumnarToRow [codegen id : 20]
Input [1]: [sum(sales)#45]

===== Subqueries =====

Subquery:1 Hosting operator id = 1 Hosting Expression = cs_sold_date_sk#5 IN dynamicpruning#6
BroadcastExchange (80)
+- * ColumnarToRow (79)
   +- CometProject (78)
      +- CometFilter (77)
         +- CometScan parquet spark_catalog.default.date_dim (76)


(unknown) Scan parquet spark_catalog.default.date_dim
Output [3]: [d_date_sk#31, d_year#46, d_moy#47]
Batched: true
Location [not included in comparison]/{warehouse_dir}/date_dim]
PushedFilters: [IsNotNull(d_year), IsNotNull(d_moy), EqualTo(d_year,2000), EqualTo(d_moy,2), IsNotNull(d_date_sk)]
ReadSchema: struct<d_date_sk:int,d_year:int,d_moy:int>

(77) CometFilter
Input [3]: [d_date_sk#31, d_year#46, d_moy#47]
Condition : ((((isnotnull(d_year#46) AND isnotnull(d_moy#47)) AND (d_year#46 = 2000)) AND (d_moy#47 = 2)) AND isnotnull(d_date_sk#31))

(78) CometProject
Input [3]: [d_date_sk#31, d_year#46, d_moy#47]
Arguments: [d_date_sk#31], [d_date_sk#31]

(79) ColumnarToRow [codegen id : 1]
Input [1]: [d_date_sk#31]

(80) BroadcastExchange
Input [1]: [d_date_sk#31]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=9]

Subquery:2 Hosting operator id = 3 Hosting Expression = ss_sold_date_sk#8 IN dynamicpruning#9
BroadcastExchange (85)
+- * ColumnarToRow (84)
   +- CometProject (83)
      +- CometFilter (82)
         +- CometScan parquet spark_catalog.default.date_dim (81)


(unknown) Scan parquet spark_catalog.default.date_dim
Output [3]: [d_date_sk#10, d_date#11, d_year#48]
Batched: true
Location [not included in comparison]/{warehouse_dir}/date_dim]
PushedFilters: [In(d_year, [2000,2001,2002,2003]), IsNotNull(d_date_sk)]
ReadSchema: struct<d_date_sk:int,d_date:date,d_year:int>

(82) CometFilter
Input [3]: [d_date_sk#10, d_date#11, d_year#48]
Condition : (d_year#48 IN (2000,2001,2002,2003) AND isnotnull(d_date_sk#10))

(83) CometProject
Input [3]: [d_date_sk#10, d_date#11, d_year#48]
Arguments: [d_date_sk#10, d_date#11], [d_date_sk#10, d_date#11]

(84) ColumnarToRow [codegen id : 1]
Input [2]: [d_date_sk#10, d_date#11]

(85) BroadcastExchange
Input [2]: [d_date_sk#10, d_date#11]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=10]

Subquery:3 Hosting operator id = 42 Hosting Expression = Subquery scalar-subquery#29, [id=#30]
* ColumnarToRow (102)
+- CometHashAggregate (101)
   +- CometColumnarExchange (100)
      +- CometHashAggregate (99)
         +- CometHashAggregate (98)
            +- CometColumnarExchange (97)
               +- RowToColumnar (96)
                  +- * HashAggregate (95)
                     +- * Project (94)
                        +- * BroadcastHashJoin Inner BuildRight (93)
                           :- * Project (91)
                           :  +- * BroadcastHashJoin Inner BuildRight (90)
                           :     :- * ColumnarToRow (88)
                           :     :  +- CometFilter (87)
                           :     :     +- CometScan parquet spark_catalog.default.store_sales (86)
                           :     +- ReusedExchange (89)
                           +- ReusedExchange (92)


(unknown) Scan parquet spark_catalog.default.store_sales
Output [4]: [ss_customer_sk#49, ss_quantity#50, ss_sales_price#51, ss_sold_date_sk#52]
Batched: true
Location: InMemoryFileIndex []
PartitionFilters: [isnotnull(ss_sold_date_sk#52), dynamicpruningexpression(ss_sold_date_sk#52 IN dynamicpruning#53)]
PushedFilters: [IsNotNull(ss_customer_sk)]
ReadSchema: struct<ss_customer_sk:int,ss_quantity:int,ss_sales_price:decimal(7,2)>

(87) CometFilter
Input [4]: [ss_customer_sk#49, ss_quantity#50, ss_sales_price#51, ss_sold_date_sk#52]
Condition : isnotnull(ss_customer_sk#49)

(88) ColumnarToRow [codegen id : 3]
Input [4]: [ss_customer_sk#49, ss_quantity#50, ss_sales_price#51, ss_sold_date_sk#52]

(89) ReusedExchange [Reuses operator id: 35]
Output [1]: [c_customer_sk#54]

(90) BroadcastHashJoin [codegen id : 3]
Left keys [1]: [ss_customer_sk#49]
Right keys [1]: [c_customer_sk#54]
Join type: Inner
Join condition: None

(91) Project [codegen id : 3]
Output [4]: [ss_quantity#50, ss_sales_price#51, ss_sold_date_sk#52, c_customer_sk#54]
Input [5]: [ss_customer_sk#49, ss_quantity#50, ss_sales_price#51, ss_sold_date_sk#52, c_customer_sk#54]

(92) ReusedExchange [Reuses operator id: 107]
Output [1]: [d_date_sk#55]

(93) BroadcastHashJoin [codegen id : 3]
Left keys [1]: [ss_sold_date_sk#52]
Right keys [1]: [d_date_sk#55]
Join type: Inner
Join condition: None

(94) Project [codegen id : 3]
Output [3]: [ss_quantity#50, ss_sales_price#51, c_customer_sk#54]
Input [5]: [ss_quantity#50, ss_sales_price#51, ss_sold_date_sk#52, c_customer_sk#54, d_date_sk#55]

(95) HashAggregate [codegen id : 3]
Input [3]: [ss_quantity#50, ss_sales_price#51, c_customer_sk#54]
Keys [1]: [c_customer_sk#54]
Functions [1]: [partial_sum((cast(ss_quantity#50 as decimal(10,0)) * ss_sales_price#51))]
Aggregate Attributes [2]: [sum#56, isEmpty#57]
Results [3]: [c_customer_sk#54, sum#58, isEmpty#59]

(96) RowToColumnar
Input [3]: [c_customer_sk#54, sum#58, isEmpty#59]

(97) CometColumnarExchange
Input [3]: [c_customer_sk#54, sum#58, isEmpty#59]
Arguments: hashpartitioning(c_customer_sk#54, 5), ENSURE_REQUIREMENTS, CometColumnarShuffle, [plan_id=11]

(98) CometHashAggregate
Input [3]: [c_customer_sk#54, sum#58, isEmpty#59]
Keys [1]: [c_customer_sk#54]
Functions [1]: [sum((cast(ss_quantity#50 as decimal(10,0)) * ss_sales_price#51))]

(99) CometHashAggregate
Input [1]: [csales#60]
Keys: []
Functions [1]: [partial_max(csales#60)]

(100) CometColumnarExchange
Input [1]: [max#61]
Arguments: SinglePartition, ENSURE_REQUIREMENTS, CometColumnarShuffle, [plan_id=12]

(101) CometHashAggregate
Input [1]: [max#61]
Keys: []
Functions [1]: [max(csales#60)]

(102) ColumnarToRow [codegen id : 4]
Input [1]: [tpcds_cmax#62]

Subquery:4 Hosting operator id = 86 Hosting Expression = ss_sold_date_sk#52 IN dynamicpruning#53
BroadcastExchange (107)
+- * ColumnarToRow (106)
   +- CometProject (105)
      +- CometFilter (104)
         +- CometScan parquet spark_catalog.default.date_dim (103)


(unknown) Scan parquet spark_catalog.default.date_dim
Output [2]: [d_date_sk#55, d_year#63]
Batched: true
Location [not included in comparison]/{warehouse_dir}/date_dim]
PushedFilters: [In(d_year, [2000,2001,2002,2003]), IsNotNull(d_date_sk)]
ReadSchema: struct<d_date_sk:int,d_year:int>

(104) CometFilter
Input [2]: [d_date_sk#55, d_year#63]
Condition : (d_year#63 IN (2000,2001,2002,2003) AND isnotnull(d_date_sk#55))

(105) CometProject
Input [2]: [d_date_sk#55, d_year#63]
Arguments: [d_date_sk#55], [d_date_sk#55]

(106) ColumnarToRow [codegen id : 1]
Input [1]: [d_date_sk#55]

(107) BroadcastExchange
Input [1]: [d_date_sk#55]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=13]

Subquery:5 Hosting operator id = 51 Hosting Expression = ws_sold_date_sk#37 IN dynamicpruning#6

Subquery:6 Hosting operator id = 61 Hosting Expression = ReusedSubquery Subquery scalar-subquery#29, [id=#30]


