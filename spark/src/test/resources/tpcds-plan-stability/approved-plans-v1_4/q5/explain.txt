== Physical Plan ==
TakeOrderedAndProject (70)
+- * HashAggregate (69)
   +- Exchange (68)
      +- * HashAggregate (67)
         +- * Expand (66)
            +- Union (65)
               :- * HashAggregate (20)
               :  +- Exchange (19)
               :     +- * HashAggregate (18)
               :        +- * Project (17)
               :           +- * BroadcastHashJoin Inner BuildRight (16)
               :              :- * Project (11)
               :              :  +- * BroadcastHashJoin Inner BuildRight (10)
               :              :     :- * ColumnarToRow (8)
               :              :     :  +- CometUnion (7)
               :              :     :     :- CometProject (3)
               :              :     :     :  +- CometFilter (2)
               :              :     :     :     +- CometScan parquet spark_catalog.default.store_sales (1)
               :              :     :     +- CometProject (6)
               :              :     :        +- CometFilter (5)
               :              :     :           +- CometScan parquet spark_catalog.default.store_returns (4)
               :              :     +- ReusedExchange (9)
               :              +- BroadcastExchange (15)
               :                 +- * ColumnarToRow (14)
               :                    +- CometFilter (13)
               :                       +- CometScan parquet spark_catalog.default.store (12)
               :- * HashAggregate (40)
               :  +- Exchange (39)
               :     +- * HashAggregate (38)
               :        +- * Project (37)
               :           +- * BroadcastHashJoin Inner BuildRight (36)
               :              :- * Project (31)
               :              :  +- * BroadcastHashJoin Inner BuildRight (30)
               :              :     :- * ColumnarToRow (28)
               :              :     :  +- CometUnion (27)
               :              :     :     :- CometProject (23)
               :              :     :     :  +- CometFilter (22)
               :              :     :     :     +- CometScan parquet spark_catalog.default.catalog_sales (21)
               :              :     :     +- CometProject (26)
               :              :     :        +- CometFilter (25)
               :              :     :           +- CometScan parquet spark_catalog.default.catalog_returns (24)
               :              :     +- ReusedExchange (29)
               :              +- BroadcastExchange (35)
               :                 +- * ColumnarToRow (34)
               :                    +- CometFilter (33)
               :                       +- CometScan parquet spark_catalog.default.catalog_page (32)
               +- * HashAggregate (64)
                  +- Exchange (63)
                     +- * HashAggregate (62)
                        +- * Project (61)
                           +- * BroadcastHashJoin Inner BuildRight (60)
                              :- * Project (55)
                              :  +- * BroadcastHashJoin Inner BuildRight (54)
                              :     :- * ColumnarToRow (52)
                              :     :  +- CometUnion (51)
                              :     :     :- CometProject (43)
                              :     :     :  +- CometFilter (42)
                              :     :     :     +- CometScan parquet spark_catalog.default.web_sales (41)
                              :     :     +- CometProject (50)
                              :     :        +- CometBroadcastHashJoin (49)
                              :     :           :- CometBroadcastExchange (45)
                              :     :           :  +- CometScan parquet spark_catalog.default.web_returns (44)
                              :     :           +- CometProject (48)
                              :     :              +- CometFilter (47)
                              :     :                 +- CometScan parquet spark_catalog.default.web_sales (46)
                              :     +- ReusedExchange (53)
                              +- BroadcastExchange (59)
                                 +- * ColumnarToRow (58)
                                    +- CometFilter (57)
                                       +- CometScan parquet spark_catalog.default.web_site (56)


(unknown) Scan parquet spark_catalog.default.store_sales
Output [4]: [ss_store_sk#1, ss_ext_sales_price#2, ss_net_profit#3, ss_sold_date_sk#4]
Batched: true
Location: InMemoryFileIndex []
PartitionFilters: [isnotnull(ss_sold_date_sk#4), dynamicpruningexpression(ss_sold_date_sk#4 IN dynamicpruning#5)]
PushedFilters: [IsNotNull(ss_store_sk)]
ReadSchema: struct<ss_store_sk:int,ss_ext_sales_price:decimal(7,2),ss_net_profit:decimal(7,2)>

(2) CometFilter
Input [4]: [ss_store_sk#1, ss_ext_sales_price#2, ss_net_profit#3, ss_sold_date_sk#4]
Condition : isnotnull(ss_store_sk#1)

(3) CometProject
Input [4]: [ss_store_sk#1, ss_ext_sales_price#2, ss_net_profit#3, ss_sold_date_sk#4]
Arguments: [store_sk#6, date_sk#7, sales_price#8, profit#9, return_amt#10, net_loss#11], [ss_store_sk#1 AS store_sk#6, ss_sold_date_sk#4 AS date_sk#7, ss_ext_sales_price#2 AS sales_price#8, ss_net_profit#3 AS profit#9, 0.00 AS return_amt#10, 0.00 AS net_loss#11]

(unknown) Scan parquet spark_catalog.default.store_returns
Output [4]: [sr_store_sk#12, sr_return_amt#13, sr_net_loss#14, sr_returned_date_sk#15]
Batched: true
Location: InMemoryFileIndex []
PartitionFilters: [isnotnull(sr_returned_date_sk#15), dynamicpruningexpression(sr_returned_date_sk#15 IN dynamicpruning#5)]
PushedFilters: [IsNotNull(sr_store_sk)]
ReadSchema: struct<sr_store_sk:int,sr_return_amt:decimal(7,2),sr_net_loss:decimal(7,2)>

(5) CometFilter
Input [4]: [sr_store_sk#12, sr_return_amt#13, sr_net_loss#14, sr_returned_date_sk#15]
Condition : isnotnull(sr_store_sk#12)

(6) CometProject
Input [4]: [sr_store_sk#12, sr_return_amt#13, sr_net_loss#14, sr_returned_date_sk#15]
Arguments: [store_sk#16, date_sk#17, sales_price#18, profit#19, return_amt#20, net_loss#21], [sr_store_sk#12 AS store_sk#16, sr_returned_date_sk#15 AS date_sk#17, 0.00 AS sales_price#18, 0.00 AS profit#19, sr_return_amt#13 AS return_amt#20, sr_net_loss#14 AS net_loss#21]

(7) CometUnion
Child 0 Input [6]: [store_sk#6, date_sk#7, sales_price#8, profit#9, return_amt#10, net_loss#11]
Child 1 Input [6]: [store_sk#16, date_sk#17, sales_price#18, profit#19, return_amt#20, net_loss#21]

(8) ColumnarToRow [codegen id : 3]
Input [6]: [store_sk#6, date_sk#7, sales_price#8, profit#9, return_amt#10, net_loss#11]

(9) ReusedExchange [Reuses operator id: 75]
Output [1]: [d_date_sk#22]

(10) BroadcastHashJoin [codegen id : 3]
Left keys [1]: [date_sk#7]
Right keys [1]: [d_date_sk#22]
Join type: Inner
Join condition: None

(11) Project [codegen id : 3]
Output [5]: [store_sk#6, sales_price#8, profit#9, return_amt#10, net_loss#11]
Input [7]: [store_sk#6, date_sk#7, sales_price#8, profit#9, return_amt#10, net_loss#11, d_date_sk#22]

(unknown) Scan parquet spark_catalog.default.store
Output [2]: [s_store_sk#23, s_store_id#24]
Batched: true
Location [not included in comparison]/{warehouse_dir}/store]
PushedFilters: [IsNotNull(s_store_sk)]
ReadSchema: struct<s_store_sk:int,s_store_id:string>

(13) CometFilter
Input [2]: [s_store_sk#23, s_store_id#24]
Condition : isnotnull(s_store_sk#23)

(14) ColumnarToRow [codegen id : 2]
Input [2]: [s_store_sk#23, s_store_id#24]

(15) BroadcastExchange
Input [2]: [s_store_sk#23, s_store_id#24]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=1]

(16) BroadcastHashJoin [codegen id : 3]
Left keys [1]: [store_sk#6]
Right keys [1]: [s_store_sk#23]
Join type: Inner
Join condition: None

(17) Project [codegen id : 3]
Output [5]: [sales_price#8, profit#9, return_amt#10, net_loss#11, s_store_id#24]
Input [7]: [store_sk#6, sales_price#8, profit#9, return_amt#10, net_loss#11, s_store_sk#23, s_store_id#24]

(18) HashAggregate [codegen id : 3]
Input [5]: [sales_price#8, profit#9, return_amt#10, net_loss#11, s_store_id#24]
Keys [1]: [s_store_id#24]
Functions [4]: [partial_sum(UnscaledValue(sales_price#8)), partial_sum(UnscaledValue(return_amt#10)), partial_sum(UnscaledValue(profit#9)), partial_sum(UnscaledValue(net_loss#11))]
Aggregate Attributes [4]: [sum#25, sum#26, sum#27, sum#28]
Results [5]: [s_store_id#24, sum#29, sum#30, sum#31, sum#32]

(19) Exchange
Input [5]: [s_store_id#24, sum#29, sum#30, sum#31, sum#32]
Arguments: hashpartitioning(s_store_id#24, 5), ENSURE_REQUIREMENTS, [plan_id=2]

(20) HashAggregate [codegen id : 4]
Input [5]: [s_store_id#24, sum#29, sum#30, sum#31, sum#32]
Keys [1]: [s_store_id#24]
Functions [4]: [sum(UnscaledValue(sales_price#8)), sum(UnscaledValue(return_amt#10)), sum(UnscaledValue(profit#9)), sum(UnscaledValue(net_loss#11))]
Aggregate Attributes [4]: [sum(UnscaledValue(sales_price#8))#33, sum(UnscaledValue(return_amt#10))#34, sum(UnscaledValue(profit#9))#35, sum(UnscaledValue(net_loss#11))#36]
Results [5]: [MakeDecimal(sum(UnscaledValue(sales_price#8))#33,17,2) AS sales#37, MakeDecimal(sum(UnscaledValue(return_amt#10))#34,17,2) AS returns#38, (MakeDecimal(sum(UnscaledValue(profit#9))#35,17,2) - MakeDecimal(sum(UnscaledValue(net_loss#11))#36,17,2)) AS profit#39, store channel AS channel#40, concat(store, s_store_id#24) AS id#41]

(unknown) Scan parquet spark_catalog.default.catalog_sales
Output [4]: [cs_catalog_page_sk#42, cs_ext_sales_price#43, cs_net_profit#44, cs_sold_date_sk#45]
Batched: true
Location: InMemoryFileIndex []
PartitionFilters: [isnotnull(cs_sold_date_sk#45), dynamicpruningexpression(cs_sold_date_sk#45 IN dynamicpruning#46)]
PushedFilters: [IsNotNull(cs_catalog_page_sk)]
ReadSchema: struct<cs_catalog_page_sk:int,cs_ext_sales_price:decimal(7,2),cs_net_profit:decimal(7,2)>

(22) CometFilter
Input [4]: [cs_catalog_page_sk#42, cs_ext_sales_price#43, cs_net_profit#44, cs_sold_date_sk#45]
Condition : isnotnull(cs_catalog_page_sk#42)

(23) CometProject
Input [4]: [cs_catalog_page_sk#42, cs_ext_sales_price#43, cs_net_profit#44, cs_sold_date_sk#45]
Arguments: [page_sk#47, date_sk#48, sales_price#49, profit#50, return_amt#51, net_loss#52], [cs_catalog_page_sk#42 AS page_sk#47, cs_sold_date_sk#45 AS date_sk#48, cs_ext_sales_price#43 AS sales_price#49, cs_net_profit#44 AS profit#50, 0.00 AS return_amt#51, 0.00 AS net_loss#52]

(unknown) Scan parquet spark_catalog.default.catalog_returns
Output [4]: [cr_catalog_page_sk#53, cr_return_amount#54, cr_net_loss#55, cr_returned_date_sk#56]
Batched: true
Location: InMemoryFileIndex []
PartitionFilters: [isnotnull(cr_returned_date_sk#56), dynamicpruningexpression(cr_returned_date_sk#56 IN dynamicpruning#46)]
PushedFilters: [IsNotNull(cr_catalog_page_sk)]
ReadSchema: struct<cr_catalog_page_sk:int,cr_return_amount:decimal(7,2),cr_net_loss:decimal(7,2)>

(25) CometFilter
Input [4]: [cr_catalog_page_sk#53, cr_return_amount#54, cr_net_loss#55, cr_returned_date_sk#56]
Condition : isnotnull(cr_catalog_page_sk#53)

(26) CometProject
Input [4]: [cr_catalog_page_sk#53, cr_return_amount#54, cr_net_loss#55, cr_returned_date_sk#56]
Arguments: [page_sk#57, date_sk#58, sales_price#59, profit#60, return_amt#61, net_loss#62], [cr_catalog_page_sk#53 AS page_sk#57, cr_returned_date_sk#56 AS date_sk#58, 0.00 AS sales_price#59, 0.00 AS profit#60, cr_return_amount#54 AS return_amt#61, cr_net_loss#55 AS net_loss#62]

(27) CometUnion
Child 0 Input [6]: [page_sk#47, date_sk#48, sales_price#49, profit#50, return_amt#51, net_loss#52]
Child 1 Input [6]: [page_sk#57, date_sk#58, sales_price#59, profit#60, return_amt#61, net_loss#62]

(28) ColumnarToRow [codegen id : 7]
Input [6]: [page_sk#47, date_sk#48, sales_price#49, profit#50, return_amt#51, net_loss#52]

(29) ReusedExchange [Reuses operator id: 75]
Output [1]: [d_date_sk#63]

(30) BroadcastHashJoin [codegen id : 7]
Left keys [1]: [date_sk#48]
Right keys [1]: [d_date_sk#63]
Join type: Inner
Join condition: None

(31) Project [codegen id : 7]
Output [5]: [page_sk#47, sales_price#49, profit#50, return_amt#51, net_loss#52]
Input [7]: [page_sk#47, date_sk#48, sales_price#49, profit#50, return_amt#51, net_loss#52, d_date_sk#63]

(unknown) Scan parquet spark_catalog.default.catalog_page
Output [2]: [cp_catalog_page_sk#64, cp_catalog_page_id#65]
Batched: true
Location [not included in comparison]/{warehouse_dir}/catalog_page]
PushedFilters: [IsNotNull(cp_catalog_page_sk)]
ReadSchema: struct<cp_catalog_page_sk:int,cp_catalog_page_id:string>

(33) CometFilter
Input [2]: [cp_catalog_page_sk#64, cp_catalog_page_id#65]
Condition : isnotnull(cp_catalog_page_sk#64)

(34) ColumnarToRow [codegen id : 6]
Input [2]: [cp_catalog_page_sk#64, cp_catalog_page_id#65]

(35) BroadcastExchange
Input [2]: [cp_catalog_page_sk#64, cp_catalog_page_id#65]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=3]

(36) BroadcastHashJoin [codegen id : 7]
Left keys [1]: [page_sk#47]
Right keys [1]: [cp_catalog_page_sk#64]
Join type: Inner
Join condition: None

(37) Project [codegen id : 7]
Output [5]: [sales_price#49, profit#50, return_amt#51, net_loss#52, cp_catalog_page_id#65]
Input [7]: [page_sk#47, sales_price#49, profit#50, return_amt#51, net_loss#52, cp_catalog_page_sk#64, cp_catalog_page_id#65]

(38) HashAggregate [codegen id : 7]
Input [5]: [sales_price#49, profit#50, return_amt#51, net_loss#52, cp_catalog_page_id#65]
Keys [1]: [cp_catalog_page_id#65]
Functions [4]: [partial_sum(UnscaledValue(sales_price#49)), partial_sum(UnscaledValue(return_amt#51)), partial_sum(UnscaledValue(profit#50)), partial_sum(UnscaledValue(net_loss#52))]
Aggregate Attributes [4]: [sum#66, sum#67, sum#68, sum#69]
Results [5]: [cp_catalog_page_id#65, sum#70, sum#71, sum#72, sum#73]

(39) Exchange
Input [5]: [cp_catalog_page_id#65, sum#70, sum#71, sum#72, sum#73]
Arguments: hashpartitioning(cp_catalog_page_id#65, 5), ENSURE_REQUIREMENTS, [plan_id=4]

(40) HashAggregate [codegen id : 8]
Input [5]: [cp_catalog_page_id#65, sum#70, sum#71, sum#72, sum#73]
Keys [1]: [cp_catalog_page_id#65]
Functions [4]: [sum(UnscaledValue(sales_price#49)), sum(UnscaledValue(return_amt#51)), sum(UnscaledValue(profit#50)), sum(UnscaledValue(net_loss#52))]
Aggregate Attributes [4]: [sum(UnscaledValue(sales_price#49))#74, sum(UnscaledValue(return_amt#51))#75, sum(UnscaledValue(profit#50))#76, sum(UnscaledValue(net_loss#52))#77]
Results [5]: [MakeDecimal(sum(UnscaledValue(sales_price#49))#74,17,2) AS sales#78, MakeDecimal(sum(UnscaledValue(return_amt#51))#75,17,2) AS returns#79, (MakeDecimal(sum(UnscaledValue(profit#50))#76,17,2) - MakeDecimal(sum(UnscaledValue(net_loss#52))#77,17,2)) AS profit#80, catalog channel AS channel#81, concat(catalog_page, cp_catalog_page_id#65) AS id#82]

(unknown) Scan parquet spark_catalog.default.web_sales
Output [4]: [ws_web_site_sk#83, ws_ext_sales_price#84, ws_net_profit#85, ws_sold_date_sk#86]
Batched: true
Location: InMemoryFileIndex []
PartitionFilters: [isnotnull(ws_sold_date_sk#86), dynamicpruningexpression(ws_sold_date_sk#86 IN dynamicpruning#87)]
PushedFilters: [IsNotNull(ws_web_site_sk)]
ReadSchema: struct<ws_web_site_sk:int,ws_ext_sales_price:decimal(7,2),ws_net_profit:decimal(7,2)>

(42) CometFilter
Input [4]: [ws_web_site_sk#83, ws_ext_sales_price#84, ws_net_profit#85, ws_sold_date_sk#86]
Condition : isnotnull(ws_web_site_sk#83)

(43) CometProject
Input [4]: [ws_web_site_sk#83, ws_ext_sales_price#84, ws_net_profit#85, ws_sold_date_sk#86]
Arguments: [wsr_web_site_sk#88, date_sk#89, sales_price#90, profit#91, return_amt#92, net_loss#93], [ws_web_site_sk#83 AS wsr_web_site_sk#88, ws_sold_date_sk#86 AS date_sk#89, ws_ext_sales_price#84 AS sales_price#90, ws_net_profit#85 AS profit#91, 0.00 AS return_amt#92, 0.00 AS net_loss#93]

(unknown) Scan parquet spark_catalog.default.web_returns
Output [5]: [wr_item_sk#94, wr_order_number#95, wr_return_amt#96, wr_net_loss#97, wr_returned_date_sk#98]
Batched: true
Location: InMemoryFileIndex []
PartitionFilters: [isnotnull(wr_returned_date_sk#98), dynamicpruningexpression(wr_returned_date_sk#98 IN dynamicpruning#87)]
ReadSchema: struct<wr_item_sk:int,wr_order_number:int,wr_return_amt:decimal(7,2),wr_net_loss:decimal(7,2)>

(45) CometBroadcastExchange
Input [5]: [wr_item_sk#94, wr_order_number#95, wr_return_amt#96, wr_net_loss#97, wr_returned_date_sk#98]
Arguments: [wr_item_sk#94, wr_order_number#95, wr_return_amt#96, wr_net_loss#97, wr_returned_date_sk#98]

(unknown) Scan parquet spark_catalog.default.web_sales
Output [4]: [ws_item_sk#99, ws_web_site_sk#100, ws_order_number#101, ws_sold_date_sk#102]
Batched: true
Location [not included in comparison]/{warehouse_dir}/web_sales]
PushedFilters: [IsNotNull(ws_item_sk), IsNotNull(ws_order_number), IsNotNull(ws_web_site_sk)]
ReadSchema: struct<ws_item_sk:int,ws_web_site_sk:int,ws_order_number:int>

(47) CometFilter
Input [4]: [ws_item_sk#99, ws_web_site_sk#100, ws_order_number#101, ws_sold_date_sk#102]
Condition : ((isnotnull(ws_item_sk#99) AND isnotnull(ws_order_number#101)) AND isnotnull(ws_web_site_sk#100))

(48) CometProject
Input [4]: [ws_item_sk#99, ws_web_site_sk#100, ws_order_number#101, ws_sold_date_sk#102]
Arguments: [ws_item_sk#99, ws_web_site_sk#100, ws_order_number#101], [ws_item_sk#99, ws_web_site_sk#100, ws_order_number#101]

(49) CometBroadcastHashJoin
Left output [5]: [wr_item_sk#94, wr_order_number#95, wr_return_amt#96, wr_net_loss#97, wr_returned_date_sk#98]
Right output [3]: [ws_item_sk#99, ws_web_site_sk#100, ws_order_number#101]
Arguments: [wr_item_sk#94, wr_order_number#95], [ws_item_sk#99, ws_order_number#101], Inner

(50) CometProject
Input [8]: [wr_item_sk#94, wr_order_number#95, wr_return_amt#96, wr_net_loss#97, wr_returned_date_sk#98, ws_item_sk#99, ws_web_site_sk#100, ws_order_number#101]
Arguments: [wsr_web_site_sk#103, date_sk#104, sales_price#105, profit#106, return_amt#107, net_loss#108], [ws_web_site_sk#100 AS wsr_web_site_sk#103, wr_returned_date_sk#98 AS date_sk#104, 0.00 AS sales_price#105, 0.00 AS profit#106, wr_return_amt#96 AS return_amt#107, wr_net_loss#97 AS net_loss#108]

(51) CometUnion
Child 0 Input [6]: [wsr_web_site_sk#88, date_sk#89, sales_price#90, profit#91, return_amt#92, net_loss#93]
Child 1 Input [6]: [wsr_web_site_sk#103, date_sk#104, sales_price#105, profit#106, return_amt#107, net_loss#108]

(52) ColumnarToRow [codegen id : 11]
Input [6]: [wsr_web_site_sk#88, date_sk#89, sales_price#90, profit#91, return_amt#92, net_loss#93]

(53) ReusedExchange [Reuses operator id: 75]
Output [1]: [d_date_sk#109]

(54) BroadcastHashJoin [codegen id : 11]
Left keys [1]: [date_sk#89]
Right keys [1]: [d_date_sk#109]
Join type: Inner
Join condition: None

(55) Project [codegen id : 11]
Output [5]: [wsr_web_site_sk#88, sales_price#90, profit#91, return_amt#92, net_loss#93]
Input [7]: [wsr_web_site_sk#88, date_sk#89, sales_price#90, profit#91, return_amt#92, net_loss#93, d_date_sk#109]

(unknown) Scan parquet spark_catalog.default.web_site
Output [2]: [web_site_sk#110, web_site_id#111]
Batched: true
Location [not included in comparison]/{warehouse_dir}/web_site]
PushedFilters: [IsNotNull(web_site_sk)]
ReadSchema: struct<web_site_sk:int,web_site_id:string>

(57) CometFilter
Input [2]: [web_site_sk#110, web_site_id#111]
Condition : isnotnull(web_site_sk#110)

(58) ColumnarToRow [codegen id : 10]
Input [2]: [web_site_sk#110, web_site_id#111]

(59) BroadcastExchange
Input [2]: [web_site_sk#110, web_site_id#111]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=5]

(60) BroadcastHashJoin [codegen id : 11]
Left keys [1]: [wsr_web_site_sk#88]
Right keys [1]: [web_site_sk#110]
Join type: Inner
Join condition: None

(61) Project [codegen id : 11]
Output [5]: [sales_price#90, profit#91, return_amt#92, net_loss#93, web_site_id#111]
Input [7]: [wsr_web_site_sk#88, sales_price#90, profit#91, return_amt#92, net_loss#93, web_site_sk#110, web_site_id#111]

(62) HashAggregate [codegen id : 11]
Input [5]: [sales_price#90, profit#91, return_amt#92, net_loss#93, web_site_id#111]
Keys [1]: [web_site_id#111]
Functions [4]: [partial_sum(UnscaledValue(sales_price#90)), partial_sum(UnscaledValue(return_amt#92)), partial_sum(UnscaledValue(profit#91)), partial_sum(UnscaledValue(net_loss#93))]
Aggregate Attributes [4]: [sum#112, sum#113, sum#114, sum#115]
Results [5]: [web_site_id#111, sum#116, sum#117, sum#118, sum#119]

(63) Exchange
Input [5]: [web_site_id#111, sum#116, sum#117, sum#118, sum#119]
Arguments: hashpartitioning(web_site_id#111, 5), ENSURE_REQUIREMENTS, [plan_id=6]

(64) HashAggregate [codegen id : 12]
Input [5]: [web_site_id#111, sum#116, sum#117, sum#118, sum#119]
Keys [1]: [web_site_id#111]
Functions [4]: [sum(UnscaledValue(sales_price#90)), sum(UnscaledValue(return_amt#92)), sum(UnscaledValue(profit#91)), sum(UnscaledValue(net_loss#93))]
Aggregate Attributes [4]: [sum(UnscaledValue(sales_price#90))#120, sum(UnscaledValue(return_amt#92))#121, sum(UnscaledValue(profit#91))#122, sum(UnscaledValue(net_loss#93))#123]
Results [5]: [MakeDecimal(sum(UnscaledValue(sales_price#90))#120,17,2) AS sales#124, MakeDecimal(sum(UnscaledValue(return_amt#92))#121,17,2) AS returns#125, (MakeDecimal(sum(UnscaledValue(profit#91))#122,17,2) - MakeDecimal(sum(UnscaledValue(net_loss#93))#123,17,2)) AS profit#126, web channel AS channel#127, concat(web_site, web_site_id#111) AS id#128]

(65) Union

(66) Expand [codegen id : 13]
Input [5]: [sales#37, returns#38, profit#39, channel#40, id#41]
Arguments: [[sales#37, returns#38, profit#39, channel#40, id#41, 0], [sales#37, returns#38, profit#39, channel#40, null, 1], [sales#37, returns#38, profit#39, null, null, 3]], [sales#37, returns#38, profit#39, channel#129, id#130, spark_grouping_id#131]

(67) HashAggregate [codegen id : 13]
Input [6]: [sales#37, returns#38, profit#39, channel#129, id#130, spark_grouping_id#131]
Keys [3]: [channel#129, id#130, spark_grouping_id#131]
Functions [3]: [partial_sum(sales#37), partial_sum(returns#38), partial_sum(profit#39)]
Aggregate Attributes [6]: [sum#132, isEmpty#133, sum#134, isEmpty#135, sum#136, isEmpty#137]
Results [9]: [channel#129, id#130, spark_grouping_id#131, sum#138, isEmpty#139, sum#140, isEmpty#141, sum#142, isEmpty#143]

(68) Exchange
Input [9]: [channel#129, id#130, spark_grouping_id#131, sum#138, isEmpty#139, sum#140, isEmpty#141, sum#142, isEmpty#143]
Arguments: hashpartitioning(channel#129, id#130, spark_grouping_id#131, 5), ENSURE_REQUIREMENTS, [plan_id=7]

(69) HashAggregate [codegen id : 14]
Input [9]: [channel#129, id#130, spark_grouping_id#131, sum#138, isEmpty#139, sum#140, isEmpty#141, sum#142, isEmpty#143]
Keys [3]: [channel#129, id#130, spark_grouping_id#131]
Functions [3]: [sum(sales#37), sum(returns#38), sum(profit#39)]
Aggregate Attributes [3]: [sum(sales#37)#144, sum(returns#38)#145, sum(profit#39)#146]
Results [5]: [channel#129, id#130, sum(sales#37)#144 AS sales#147, sum(returns#38)#145 AS returns#148, sum(profit#39)#146 AS profit#149]

(70) TakeOrderedAndProject
Input [5]: [channel#129, id#130, sales#147, returns#148, profit#149]
Arguments: 100, [channel#129 ASC NULLS FIRST, id#130 ASC NULLS FIRST], [channel#129, id#130, sales#147, returns#148, profit#149]

===== Subqueries =====

Subquery:1 Hosting operator id = 1 Hosting Expression = ss_sold_date_sk#4 IN dynamicpruning#5
BroadcastExchange (75)
+- * ColumnarToRow (74)
   +- CometProject (73)
      +- CometFilter (72)
         +- CometScan parquet spark_catalog.default.date_dim (71)


(unknown) Scan parquet spark_catalog.default.date_dim
Output [2]: [d_date_sk#22, d_date#150]
Batched: true
Location [not included in comparison]/{warehouse_dir}/date_dim]
PushedFilters: [IsNotNull(d_date), GreaterThanOrEqual(d_date,2000-08-23), LessThanOrEqual(d_date,2000-09-06), IsNotNull(d_date_sk)]
ReadSchema: struct<d_date_sk:int,d_date:date>

(72) CometFilter
Input [2]: [d_date_sk#22, d_date#150]
Condition : (((isnotnull(d_date#150) AND (d_date#150 >= 2000-08-23)) AND (d_date#150 <= 2000-09-06)) AND isnotnull(d_date_sk#22))

(73) CometProject
Input [2]: [d_date_sk#22, d_date#150]
Arguments: [d_date_sk#22], [d_date_sk#22]

(74) ColumnarToRow [codegen id : 1]
Input [1]: [d_date_sk#22]

(75) BroadcastExchange
Input [1]: [d_date_sk#22]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=8]

Subquery:2 Hosting operator id = 4 Hosting Expression = sr_returned_date_sk#15 IN dynamicpruning#5

Subquery:3 Hosting operator id = 21 Hosting Expression = cs_sold_date_sk#45 IN dynamicpruning#5

Subquery:4 Hosting operator id = 24 Hosting Expression = cr_returned_date_sk#56 IN dynamicpruning#5

Subquery:5 Hosting operator id = 41 Hosting Expression = ws_sold_date_sk#86 IN dynamicpruning#5

Subquery:6 Hosting operator id = 44 Hosting Expression = wr_returned_date_sk#98 IN dynamicpruning#5


