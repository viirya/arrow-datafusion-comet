== Physical Plan ==
* ColumnarToRow (55)
+- CometHashAggregate (54)
   +- CometColumnarExchange (53)
      +- RowToColumnar (52)
         +- * HashAggregate (51)
            +- * Project (50)
               +- * BroadcastHashJoin LeftSemi BuildRight (49)
                  :- * BroadcastHashJoin LeftSemi BuildRight (33)
                  :  :- * ColumnarToRow (17)
                  :  :  +- CometHashAggregate (16)
                  :  :     +- CometColumnarExchange (15)
                  :  :        +- RowToColumnar (14)
                  :  :           +- * HashAggregate (13)
                  :  :              +- * Project (12)
                  :  :                 +- * BroadcastHashJoin Inner BuildRight (11)
                  :  :                    :- * Project (6)
                  :  :                    :  +- * BroadcastHashJoin Inner BuildRight (5)
                  :  :                    :     :- * ColumnarToRow (3)
                  :  :                    :     :  +- CometFilter (2)
                  :  :                    :     :     +- CometScan parquet spark_catalog.default.store_sales (1)
                  :  :                    :     +- ReusedExchange (4)
                  :  :                    +- BroadcastExchange (10)
                  :  :                       +- * ColumnarToRow (9)
                  :  :                          +- CometFilter (8)
                  :  :                             +- CometScan parquet spark_catalog.default.customer (7)
                  :  +- BroadcastExchange (32)
                  :     +- * ColumnarToRow (31)
                  :        +- CometHashAggregate (30)
                  :           +- CometColumnarExchange (29)
                  :              +- RowToColumnar (28)
                  :                 +- * HashAggregate (27)
                  :                    +- * Project (26)
                  :                       +- * BroadcastHashJoin Inner BuildRight (25)
                  :                          :- * Project (23)
                  :                          :  +- * BroadcastHashJoin Inner BuildRight (22)
                  :                          :     :- * ColumnarToRow (20)
                  :                          :     :  +- CometFilter (19)
                  :                          :     :     +- CometScan parquet spark_catalog.default.catalog_sales (18)
                  :                          :     +- ReusedExchange (21)
                  :                          +- ReusedExchange (24)
                  +- BroadcastExchange (48)
                     +- * ColumnarToRow (47)
                        +- CometHashAggregate (46)
                           +- CometColumnarExchange (45)
                              +- RowToColumnar (44)
                                 +- * HashAggregate (43)
                                    +- * Project (42)
                                       +- * BroadcastHashJoin Inner BuildRight (41)
                                          :- * Project (39)
                                          :  +- * BroadcastHashJoin Inner BuildRight (38)
                                          :     :- * ColumnarToRow (36)
                                          :     :  +- CometFilter (35)
                                          :     :     +- CometScan parquet spark_catalog.default.web_sales (34)
                                          :     +- ReusedExchange (37)
                                          +- ReusedExchange (40)


(unknown) Scan parquet spark_catalog.default.store_sales
Output [2]: [ss_customer_sk#1, ss_sold_date_sk#2]
Batched: true
Location: InMemoryFileIndex []
PartitionFilters: [isnotnull(ss_sold_date_sk#2), dynamicpruningexpression(ss_sold_date_sk#2 IN dynamicpruning#3)]
PushedFilters: [IsNotNull(ss_customer_sk)]
ReadSchema: struct<ss_customer_sk:int>

(2) CometFilter
Input [2]: [ss_customer_sk#1, ss_sold_date_sk#2]
Condition : isnotnull(ss_customer_sk#1)

(3) ColumnarToRow [codegen id : 3]
Input [2]: [ss_customer_sk#1, ss_sold_date_sk#2]

(4) ReusedExchange [Reuses operator id: 60]
Output [2]: [d_date_sk#4, d_date#5]

(5) BroadcastHashJoin [codegen id : 3]
Left keys [1]: [ss_sold_date_sk#2]
Right keys [1]: [d_date_sk#4]
Join type: Inner
Join condition: None

(6) Project [codegen id : 3]
Output [2]: [ss_customer_sk#1, d_date#5]
Input [4]: [ss_customer_sk#1, ss_sold_date_sk#2, d_date_sk#4, d_date#5]

(unknown) Scan parquet spark_catalog.default.customer
Output [3]: [c_customer_sk#6, c_first_name#7, c_last_name#8]
Batched: true
Location [not included in comparison]/{warehouse_dir}/customer]
PushedFilters: [IsNotNull(c_customer_sk)]
ReadSchema: struct<c_customer_sk:int,c_first_name:string,c_last_name:string>

(8) CometFilter
Input [3]: [c_customer_sk#6, c_first_name#7, c_last_name#8]
Condition : isnotnull(c_customer_sk#6)

(9) ColumnarToRow [codegen id : 2]
Input [3]: [c_customer_sk#6, c_first_name#7, c_last_name#8]

(10) BroadcastExchange
Input [3]: [c_customer_sk#6, c_first_name#7, c_last_name#8]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=1]

(11) BroadcastHashJoin [codegen id : 3]
Left keys [1]: [ss_customer_sk#1]
Right keys [1]: [c_customer_sk#6]
Join type: Inner
Join condition: None

(12) Project [codegen id : 3]
Output [3]: [c_last_name#8, c_first_name#7, d_date#5]
Input [5]: [ss_customer_sk#1, d_date#5, c_customer_sk#6, c_first_name#7, c_last_name#8]

(13) HashAggregate [codegen id : 3]
Input [3]: [c_last_name#8, c_first_name#7, d_date#5]
Keys [3]: [c_last_name#8, c_first_name#7, d_date#5]
Functions: []
Aggregate Attributes: []
Results [3]: [c_last_name#8, c_first_name#7, d_date#5]

(14) RowToColumnar
Input [3]: [c_last_name#8, c_first_name#7, d_date#5]

(15) CometColumnarExchange
Input [3]: [c_last_name#8, c_first_name#7, d_date#5]
Arguments: hashpartitioning(c_last_name#8, c_first_name#7, d_date#5, 5), ENSURE_REQUIREMENTS, CometColumnarShuffle, [plan_id=2]

(16) CometHashAggregate
Input [3]: [c_last_name#8, c_first_name#7, d_date#5]
Keys [3]: [c_last_name#8, c_first_name#7, d_date#5]
Functions: []

(17) ColumnarToRow [codegen id : 12]
Input [3]: [c_last_name#8, c_first_name#7, d_date#5]

(unknown) Scan parquet spark_catalog.default.catalog_sales
Output [2]: [cs_bill_customer_sk#9, cs_sold_date_sk#10]
Batched: true
Location: InMemoryFileIndex []
PartitionFilters: [isnotnull(cs_sold_date_sk#10), dynamicpruningexpression(cs_sold_date_sk#10 IN dynamicpruning#11)]
PushedFilters: [IsNotNull(cs_bill_customer_sk)]
ReadSchema: struct<cs_bill_customer_sk:int>

(19) CometFilter
Input [2]: [cs_bill_customer_sk#9, cs_sold_date_sk#10]
Condition : isnotnull(cs_bill_customer_sk#9)

(20) ColumnarToRow [codegen id : 6]
Input [2]: [cs_bill_customer_sk#9, cs_sold_date_sk#10]

(21) ReusedExchange [Reuses operator id: 60]
Output [2]: [d_date_sk#12, d_date#13]

(22) BroadcastHashJoin [codegen id : 6]
Left keys [1]: [cs_sold_date_sk#10]
Right keys [1]: [d_date_sk#12]
Join type: Inner
Join condition: None

(23) Project [codegen id : 6]
Output [2]: [cs_bill_customer_sk#9, d_date#13]
Input [4]: [cs_bill_customer_sk#9, cs_sold_date_sk#10, d_date_sk#12, d_date#13]

(24) ReusedExchange [Reuses operator id: 10]
Output [3]: [c_customer_sk#14, c_first_name#15, c_last_name#16]

(25) BroadcastHashJoin [codegen id : 6]
Left keys [1]: [cs_bill_customer_sk#9]
Right keys [1]: [c_customer_sk#14]
Join type: Inner
Join condition: None

(26) Project [codegen id : 6]
Output [3]: [c_last_name#16, c_first_name#15, d_date#13]
Input [5]: [cs_bill_customer_sk#9, d_date#13, c_customer_sk#14, c_first_name#15, c_last_name#16]

(27) HashAggregate [codegen id : 6]
Input [3]: [c_last_name#16, c_first_name#15, d_date#13]
Keys [3]: [c_last_name#16, c_first_name#15, d_date#13]
Functions: []
Aggregate Attributes: []
Results [3]: [c_last_name#16, c_first_name#15, d_date#13]

(28) RowToColumnar
Input [3]: [c_last_name#16, c_first_name#15, d_date#13]

(29) CometColumnarExchange
Input [3]: [c_last_name#16, c_first_name#15, d_date#13]
Arguments: hashpartitioning(c_last_name#16, c_first_name#15, d_date#13, 5), ENSURE_REQUIREMENTS, CometColumnarShuffle, [plan_id=3]

(30) CometHashAggregate
Input [3]: [c_last_name#16, c_first_name#15, d_date#13]
Keys [3]: [c_last_name#16, c_first_name#15, d_date#13]
Functions: []

(31) ColumnarToRow [codegen id : 7]
Input [3]: [c_last_name#16, c_first_name#15, d_date#13]

(32) BroadcastExchange
Input [3]: [c_last_name#16, c_first_name#15, d_date#13]
Arguments: HashedRelationBroadcastMode(List(coalesce(input[0, string, true], ), isnull(input[0, string, true]), coalesce(input[1, string, true], ), isnull(input[1, string, true]), coalesce(input[2, date, true], 1970-01-01), isnull(input[2, date, true])),false), [plan_id=4]

(33) BroadcastHashJoin [codegen id : 12]
Left keys [6]: [coalesce(c_last_name#8, ), isnull(c_last_name#8), coalesce(c_first_name#7, ), isnull(c_first_name#7), coalesce(d_date#5, 1970-01-01), isnull(d_date#5)]
Right keys [6]: [coalesce(c_last_name#16, ), isnull(c_last_name#16), coalesce(c_first_name#15, ), isnull(c_first_name#15), coalesce(d_date#13, 1970-01-01), isnull(d_date#13)]
Join type: LeftSemi
Join condition: None

(unknown) Scan parquet spark_catalog.default.web_sales
Output [2]: [ws_bill_customer_sk#17, ws_sold_date_sk#18]
Batched: true
Location: InMemoryFileIndex []
PartitionFilters: [isnotnull(ws_sold_date_sk#18), dynamicpruningexpression(ws_sold_date_sk#18 IN dynamicpruning#19)]
PushedFilters: [IsNotNull(ws_bill_customer_sk)]
ReadSchema: struct<ws_bill_customer_sk:int>

(35) CometFilter
Input [2]: [ws_bill_customer_sk#17, ws_sold_date_sk#18]
Condition : isnotnull(ws_bill_customer_sk#17)

(36) ColumnarToRow [codegen id : 10]
Input [2]: [ws_bill_customer_sk#17, ws_sold_date_sk#18]

(37) ReusedExchange [Reuses operator id: 60]
Output [2]: [d_date_sk#20, d_date#21]

(38) BroadcastHashJoin [codegen id : 10]
Left keys [1]: [ws_sold_date_sk#18]
Right keys [1]: [d_date_sk#20]
Join type: Inner
Join condition: None

(39) Project [codegen id : 10]
Output [2]: [ws_bill_customer_sk#17, d_date#21]
Input [4]: [ws_bill_customer_sk#17, ws_sold_date_sk#18, d_date_sk#20, d_date#21]

(40) ReusedExchange [Reuses operator id: 10]
Output [3]: [c_customer_sk#22, c_first_name#23, c_last_name#24]

(41) BroadcastHashJoin [codegen id : 10]
Left keys [1]: [ws_bill_customer_sk#17]
Right keys [1]: [c_customer_sk#22]
Join type: Inner
Join condition: None

(42) Project [codegen id : 10]
Output [3]: [c_last_name#24, c_first_name#23, d_date#21]
Input [5]: [ws_bill_customer_sk#17, d_date#21, c_customer_sk#22, c_first_name#23, c_last_name#24]

(43) HashAggregate [codegen id : 10]
Input [3]: [c_last_name#24, c_first_name#23, d_date#21]
Keys [3]: [c_last_name#24, c_first_name#23, d_date#21]
Functions: []
Aggregate Attributes: []
Results [3]: [c_last_name#24, c_first_name#23, d_date#21]

(44) RowToColumnar
Input [3]: [c_last_name#24, c_first_name#23, d_date#21]

(45) CometColumnarExchange
Input [3]: [c_last_name#24, c_first_name#23, d_date#21]
Arguments: hashpartitioning(c_last_name#24, c_first_name#23, d_date#21, 5), ENSURE_REQUIREMENTS, CometColumnarShuffle, [plan_id=5]

(46) CometHashAggregate
Input [3]: [c_last_name#24, c_first_name#23, d_date#21]
Keys [3]: [c_last_name#24, c_first_name#23, d_date#21]
Functions: []

(47) ColumnarToRow [codegen id : 11]
Input [3]: [c_last_name#24, c_first_name#23, d_date#21]

(48) BroadcastExchange
Input [3]: [c_last_name#24, c_first_name#23, d_date#21]
Arguments: HashedRelationBroadcastMode(List(coalesce(input[0, string, true], ), isnull(input[0, string, true]), coalesce(input[1, string, true], ), isnull(input[1, string, true]), coalesce(input[2, date, true], 1970-01-01), isnull(input[2, date, true])),false), [plan_id=6]

(49) BroadcastHashJoin [codegen id : 12]
Left keys [6]: [coalesce(c_last_name#8, ), isnull(c_last_name#8), coalesce(c_first_name#7, ), isnull(c_first_name#7), coalesce(d_date#5, 1970-01-01), isnull(d_date#5)]
Right keys [6]: [coalesce(c_last_name#24, ), isnull(c_last_name#24), coalesce(c_first_name#23, ), isnull(c_first_name#23), coalesce(d_date#21, 1970-01-01), isnull(d_date#21)]
Join type: LeftSemi
Join condition: None

(50) Project [codegen id : 12]
Output: []
Input [3]: [c_last_name#8, c_first_name#7, d_date#5]

(51) HashAggregate [codegen id : 12]
Input: []
Keys: []
Functions [1]: [partial_count(1)]
Aggregate Attributes [1]: [count#25]
Results [1]: [count#26]

(52) RowToColumnar
Input [1]: [count#26]

(53) CometColumnarExchange
Input [1]: [count#26]
Arguments: SinglePartition, ENSURE_REQUIREMENTS, CometColumnarShuffle, [plan_id=7]

(54) CometHashAggregate
Input [1]: [count#26]
Keys: []
Functions [1]: [count(1)]

(55) ColumnarToRow [codegen id : 13]
Input [1]: [count(1)#27]

===== Subqueries =====

Subquery:1 Hosting operator id = 1 Hosting Expression = ss_sold_date_sk#2 IN dynamicpruning#3
BroadcastExchange (60)
+- * ColumnarToRow (59)
   +- CometProject (58)
      +- CometFilter (57)
         +- CometScan parquet spark_catalog.default.date_dim (56)


(unknown) Scan parquet spark_catalog.default.date_dim
Output [3]: [d_date_sk#4, d_date#5, d_month_seq#28]
Batched: true
Location [not included in comparison]/{warehouse_dir}/date_dim]
PushedFilters: [IsNotNull(d_month_seq), GreaterThanOrEqual(d_month_seq,1200), LessThanOrEqual(d_month_seq,1211), IsNotNull(d_date_sk)]
ReadSchema: struct<d_date_sk:int,d_date:date,d_month_seq:int>

(57) CometFilter
Input [3]: [d_date_sk#4, d_date#5, d_month_seq#28]
Condition : (((isnotnull(d_month_seq#28) AND (d_month_seq#28 >= 1200)) AND (d_month_seq#28 <= 1211)) AND isnotnull(d_date_sk#4))

(58) CometProject
Input [3]: [d_date_sk#4, d_date#5, d_month_seq#28]
Arguments: [d_date_sk#4, d_date#5], [d_date_sk#4, d_date#5]

(59) ColumnarToRow [codegen id : 1]
Input [2]: [d_date_sk#4, d_date#5]

(60) BroadcastExchange
Input [2]: [d_date_sk#4, d_date#5]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=8]

Subquery:2 Hosting operator id = 18 Hosting Expression = cs_sold_date_sk#10 IN dynamicpruning#3

Subquery:3 Hosting operator id = 34 Hosting Expression = ws_sold_date_sk#18 IN dynamicpruning#3


